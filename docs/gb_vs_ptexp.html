<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Annie Xie" />

<meta name="date" content="2025-09-04" />

<title>gb_vs_ptexp</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.5.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet" />

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/main/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>



<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">covariance_decomps_dsc</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/xxie6/covariance_decomps_dsc">
    <span class="fab fa-github"></span>
     
    Source code
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">gb_vs_ptexp</h1>
<h4 class="author">Annie Xie</h4>
<h4 class="date">2025-09-04</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span>
workflowr <span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span>
</a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2025-09-08
</p>
<p>
<strong>Checks:</strong> <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 7
<span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> 0
</p>
<p>
<strong>Knit directory:</strong> <code>covariance_decomps_dsc/</code>
<span class="glyphicon glyphicon-question-sign" aria-hidden="true"
title="This is the local directory in which the code in this file was executed.">
</span>
</p>
<p>
This reproducible <a href="https://rmarkdown.rstudio.com">R Markdown</a>
analysis was created with <a
  href="https://github.com/workflowr/workflowr">workflowr</a> (version
1.7.1). The <em>Checks</em> tab describes the reproducibility checks
that were applied when the results were created. The <em>Past
versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguptodate">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>R Markdown file:</strong> up-to-date
</a>
</p>
</div>
<div id="strongRMarkdownfilestronguptodate"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great! Since the R Markdown file has been committed to the Git
repository, you know the exact version of the code that produced these
results.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the
global environment can affect the analysis in your R Markdown file in
unknown ways. For reproduciblity it’s best to always run the code in an
empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20250203code">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Seed:</strong>
<code>set.seed(20250203)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20250203code"
class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20250203)</code> was run prior to running
the code in the R Markdown file. Setting a seed ensures that any results
that rely on randomness, e.g. subsampling or permutations, are
reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Session information:</strong>
recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package
versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be
confident that you successfully produced the results during this
run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr
project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomxxie6covariancedecompsdsctreeaf05184e4928f7dee8a42d53d7a8c31cd0997fc4targetblankaf05184a">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Repository version:</strong>
<a href="https://github.com/xxie6/covariance_decomps_dsc/tree/af05184e4928f7dee8a42d53d7a8c31cd0997fc4" target="_blank">af05184</a>
</a>
</p>
</div>
<div
id="strongRepositoryversionstrongahrefhttpsgithubcomxxie6covariancedecompsdsctreeaf05184e4928f7dee8a42d53d7a8c31cd0997fc4targetblankaf05184a"
class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development
and connecting the code version to the results is critical for
reproducibility.
</p>
<p>
The results in this page were generated with repository version
<a href="https://github.com/xxie6/covariance_decomps_dsc/tree/af05184e4928f7dee8a42d53d7a8c31cd0997fc4" target="_blank">af05184</a>.
See the <em>Past versions</em> tab to see a history of the changes made
to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for
the analysis have been committed to Git prior to generating the results
(you can use <code>wflow_publish</code> or
<code>wflow_git_commit</code>). workflowr only checks the R Markdown
file, but you know if there are other scripts or data files that it
depends on. Below is the status of the Git repository when the results
were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .DS_Store
    Ignored:    .Rhistory
    Ignored:    data/.DS_Store
    Ignored:    data/adclus_cov_comp_dsc_ex/.DS_Store
    Ignored:    data/adclus_same_init_dsc_ex/.DS_Store

Untracked files:
    Untracked:  analysis/unbalanced_tree_analysis.Rmd

Unstaged changes:
    Modified:   analysis/additive_clustering_comparison_pt2.Rmd
    Modified:   analysis/input_K_comparison_pt2.Rmd
    Modified:   analysis/pt_laplace_split_init_comparison_pt2.Rmd

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not
included in this status report because it is ok for generated content to
have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the repository in which changes were
made to the R Markdown (<code>analysis/gb_vs_ptexp.Rmd</code>) and HTML
(<code>docs/gb_vs_ptexp.html</code>) files. If you’ve configured a
remote Git repository (see <code>?wflow_git_remote</code>), click on the
hyperlinks in the table below to view the files as they were in that
past version.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/xxie6/covariance_decomps_dsc/blob/af05184e4928f7dee8a42d53d7a8c31cd0997fc4/analysis/gb_vs_ptexp.Rmd" target="_blank">af05184</a>
</td>
<td>
Annie Xie
</td>
<td>
2025-09-08
</td>
<td>
Add unbalanced tree setting to comparisons
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/xxie6/covariance_decomps_dsc/105ca5e559edb29f4082fcfdc39c72c52e5a0d3c/docs/gb_vs_ptexp.html" target="_blank">105ca5e</a>
</td>
<td>
Annie Xie
</td>
<td>
2025-09-08
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/xxie6/covariance_decomps_dsc/blob/d19fb9497f954c6e2f9908bd6a40d9a292d77332/analysis/gb_vs_ptexp.Rmd" target="_blank">d19fb94</a>
</td>
<td>
Annie Xie
</td>
<td>
2025-09-08
</td>
<td>
Add comparison of gen. binary vs pt-exp prior
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>In this analysis, I am interesting in comparing the
additive-clustering style methods (e.g. the empirical Bayes methods with
generalized binary prior) to the (sparse) symmetric NMF style methods
(e.g. the empirical Bayes methods with point-exponential prior).</p>
<pre class="r"><code>library(dplyr)
library(ggplot2)
library(pheatmap)</code></pre>
<pre class="r"><code>source(&#39;code/visualization_functions.R&#39;)</code></pre>
</div>
<div id="prepare-the-dsc-data" class="section level1">
<h1>Prepare the DSC data</h1>
<pre class="r"><code>dscout &lt;- readRDS(&quot;data/dsc_results_df.rds&quot;)
dim(dscout)</code></pre>
<pre><code>[1] 8000   11</code></pre>
<p>I decided to focus on the backfit variant of the empirical Bayes
matrix factorization methods. I also decided to focus on the variant of
SINDCLUS and SYMPRES that does not explicitly model an intercept. So I
clean the data to only include these variants.</p>
<pre class="r"><code>dscout &lt;- dscout %&gt;% filter((is.na(analyze.additive_term) == TRUE &amp; is.na(analyze.backfit) == TRUE) | (analyze.additive_term == &#39;FALSE&#39; | analyze.backfit == &#39;TRUE&#39;)) %&gt;% select(!(analyze.off_diagonal))</code></pre>
<p>I also filter out other settings we’re not interested in (e.g. the
input <span class="math inline">\(K\)</span> being misspecified).</p>
<pre class="r"><code>dscout &lt;- dscout %&gt;% filter(analyze.Kmax_factor == 1)</code></pre>
</div>
<div id="balanced-tree-setting" class="section level1">
<h1>Balanced Tree Setting</h1>
<p>I will first consider the balanced tree setting. This setting is one
of the hardest settings due to the non-identifiability of the
representation.</p>
<div id="crossproduct-similarity" class="section level2">
<h2>Crossproduct Similarity</h2>
<p>This is the average crossproduct similarity for each method in the
balanced tree setting:</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;baltree_4pop&#39;, score == &#39;crossprod_similarity&#39;) %&gt;% group_by(analyze, analyze.ebnm_fn) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, analyze.ebnm_fn)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 14 × 3
# Groups:   analyze [9]
   analyze                    analyze.ebnm_fn               avg_result
   &lt;chr&gt;                      &lt;chr&gt;                              &lt;dbl&gt;
 1 codesymnmf                 &lt;NA&gt;                               0.931
 2 ebcd                       ebnm::ebnm_generalized_binary      0.636
 3 ebcd                       ebnm::ebnm_point_exponential       0.620
 4 ebmfcov_diag               ebnm::ebnm_generalized_binary      0.421
 5 ebmfcov_diag               ebnm::ebnm_point_exponential       0.339
 6 flash_normalf              ebnm::ebnm_generalized_binary      0.700
 7 flash_normalf              ebnm::ebnm_point_exponential       0.555
 8 gbcd                       ebnm::ebnm_generalized_binary      0.996
 9 gbcd                       ebnm::ebnm_point_exponential       0.995
10 laplace_split_ebmfcov_diag ebnm::ebnm_generalized_binary      0.996
11 laplace_split_ebmfcov_diag ebnm::ebnm_point_exponential       0.983
12 pca                        &lt;NA&gt;                               0.432
13 sindclus                   &lt;NA&gt;                               0.935
14 sympres                    &lt;NA&gt;                               0.905</code></pre>
<p>For the empirical Bayes methods, the point-exponential variants
performed worse than the generalized-binary variants (though in some
cases it is only slightly worse). I don’t think this is too surprising
because this setting has non-identifiability issues, and I can imagine
the point-exponential prior converging to factorizations where the
factors are not close to binary.</p>
</div>
<div
id="proportion-of-true-factors-that-are-highly-similar-to-an-estimated-factor"
class="section level2">
<h2>Proportion of true factors that are highly similar to an estimated
factor</h2>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;baltree_4pop&#39;, score == &#39;prop_true_high_cos_sim&#39;) %&gt;% group_by(analyze, analyze.ebnm_fn) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, analyze.ebnm_fn)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 14 × 3
# Groups:   analyze [9]
   analyze                    analyze.ebnm_fn               avg_result
   &lt;chr&gt;                      &lt;chr&gt;                              &lt;dbl&gt;
 1 codesymnmf                 &lt;NA&gt;                               0.871
 2 ebcd                       ebnm::ebnm_generalized_binary      0.6  
 3 ebcd                       ebnm::ebnm_point_exponential       0.614
 4 ebmfcov_diag               ebnm::ebnm_generalized_binary      0.443
 5 ebmfcov_diag               ebnm::ebnm_point_exponential       0.4  
 6 flash_normalf              ebnm::ebnm_generalized_binary      0.529
 7 flash_normalf              ebnm::ebnm_point_exponential       0.743
 8 gbcd                       ebnm::ebnm_generalized_binary      1    
 9 gbcd                       ebnm::ebnm_point_exponential       1    
10 laplace_split_ebmfcov_diag ebnm::ebnm_generalized_binary      0.986
11 laplace_split_ebmfcov_diag ebnm::ebnm_point_exponential       1    
12 pca                        &lt;NA&gt;                               0.143
13 sindclus                   &lt;NA&gt;                               0.929
14 sympres                    &lt;NA&gt;                               0.871</code></pre>
<p>Interestingly, for Flash with normal prior on F, using the previous
metric it looked like point-exponential performed worse than generalized
binary. But in this metric, it looks like the reverse is true. This is
unexpected, and I don’t have an explanation for this yet.</p>
</div>
</div>
<div id="unbalanced-non-overlapping" class="section level1">
<h1>Unbalanced Non-overlapping</h1>
<p>I will now consider the unbalanced non-overlapping setting. This
setting should be the easiest of the four settings.</p>
<div id="crossproduct-similarity-1" class="section level2">
<h2>Crossproduct Similarity</h2>
<p>This is the average crossproduct similarity for each method:</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes != &#39;rep(40, 4)&#39;, score == &#39;crossprod_similarity&#39;) %&gt;% group_by(analyze, analyze.ebnm_fn) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, analyze.ebnm_fn)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 14 × 3
# Groups:   analyze [9]
   analyze                    analyze.ebnm_fn               avg_result
   &lt;chr&gt;                      &lt;chr&gt;                              &lt;dbl&gt;
 1 codesymnmf                 &lt;NA&gt;                               0.999
 2 ebcd                       ebnm::ebnm_generalized_binary      1.00 
 3 ebcd                       ebnm::ebnm_point_exponential       1.00 
 4 ebmfcov_diag               ebnm::ebnm_generalized_binary      1.00 
 5 ebmfcov_diag               ebnm::ebnm_point_exponential       0.999
 6 flash_normalf              ebnm::ebnm_generalized_binary      0.973
 7 flash_normalf              ebnm::ebnm_point_exponential       1.00 
 8 gbcd                       ebnm::ebnm_generalized_binary      1.00 
 9 gbcd                       ebnm::ebnm_point_exponential       0.995
10 laplace_split_ebmfcov_diag ebnm::ebnm_generalized_binary      1.00 
11 laplace_split_ebmfcov_diag ebnm::ebnm_point_exponential       0.999
12 pca                        &lt;NA&gt;                               0.988
13 sindclus                   &lt;NA&gt;                               0.832
14 sympres                    &lt;NA&gt;                               0.848</code></pre>
<p>For most of the empirical Bayes methods, point-exponential performed
the same or a little bit worse. However, for Flash with the normal prior
on F, the point-exponential prior performed a little better than the
generalized-binary prior. In my experience, the point-exponential prior
is better with shrinking small values down to zero, so maybe that is why
it is performing better? That fact is not unique to this method though,
so this requires some more investigation. Furthermore, SINDCLUS and
SYMPRES perform noticeably worse than CoDesymNMF in this setting.</p>
</div>
<div
id="proportion-of-true-factors-that-are-highly-similar-to-an-estimated-factor-1"
class="section level2">
<h2>Proportion of true factors that are highly similar to an estimated
factor</h2>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes != &#39;rep(40, 4)&#39;, score == &#39;prop_true_high_cos_sim&#39;) %&gt;% group_by(analyze, analyze.ebnm_fn) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, analyze.ebnm_fn)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 14 × 3
# Groups:   analyze [9]
   analyze                    analyze.ebnm_fn               avg_result
   &lt;chr&gt;                      &lt;chr&gt;                              &lt;dbl&gt;
 1 codesymnmf                 &lt;NA&gt;                                1   
 2 ebcd                       ebnm::ebnm_generalized_binary       1   
 3 ebcd                       ebnm::ebnm_point_exponential        1   
 4 ebmfcov_diag               ebnm::ebnm_generalized_binary       1   
 5 ebmfcov_diag               ebnm::ebnm_point_exponential        1   
 6 flash_normalf              ebnm::ebnm_generalized_binary       0.9 
 7 flash_normalf              ebnm::ebnm_point_exponential        1   
 8 gbcd                       ebnm::ebnm_generalized_binary       1   
 9 gbcd                       ebnm::ebnm_point_exponential        1   
10 laplace_split_ebmfcov_diag ebnm::ebnm_generalized_binary       1   
11 laplace_split_ebmfcov_diag ebnm::ebnm_point_exponential        1   
12 pca                        &lt;NA&gt;                                1   
13 sindclus                   &lt;NA&gt;                                0.75
14 sympres                    &lt;NA&gt;                                0.75</code></pre>
<p>For Flash with normal prior on F, this metric also suggests that the
point-exponential prior performs a little better than the generalized
binary.</p>
</div>
</div>
<div id="balanced-non-overlapping" class="section level1">
<h1>Balanced Non-overlapping</h1>
<p>I will now consider the balanced non-overlapping setting. This
setting should be harder than the unbalanced non-overlapping
setting.</p>
<div id="crossproduct-similarity-2" class="section level2">
<h2>Crossproduct Similarity</h2>
<p>This is the average crossproduct similarity for each method:</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes == &#39;rep(40, 4)&#39;, score == &#39;crossprod_similarity&#39;) %&gt;% group_by(analyze, analyze.ebnm_fn) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, analyze.ebnm_fn)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 14 × 3
# Groups:   analyze [9]
   analyze                    analyze.ebnm_fn               avg_result
   &lt;chr&gt;                      &lt;chr&gt;                              &lt;dbl&gt;
 1 codesymnmf                 &lt;NA&gt;                               0.999
 2 ebcd                       ebnm::ebnm_generalized_binary      1.00 
 3 ebcd                       ebnm::ebnm_point_exponential       1.00 
 4 ebmfcov_diag               ebnm::ebnm_generalized_binary      0.967
 5 ebmfcov_diag               ebnm::ebnm_point_exponential       0.940
 6 flash_normalf              ebnm::ebnm_generalized_binary      0.892
 7 flash_normalf              ebnm::ebnm_point_exponential       1.00 
 8 gbcd                       ebnm::ebnm_generalized_binary      0.999
 9 gbcd                       ebnm::ebnm_point_exponential       0.973
10 laplace_split_ebmfcov_diag ebnm::ebnm_generalized_binary      1.00 
11 laplace_split_ebmfcov_diag ebnm::ebnm_point_exponential       0.999
12 pca                        &lt;NA&gt;                               0.743
13 sindclus                   &lt;NA&gt;                               0.927
14 sympres                    &lt;NA&gt;                               0.876</code></pre>
<p>We see a similar phenomenon to the unbalanced non-overlapping case –
for most of the empirical Bayes methods, point-exponential performed the
same or a little bit worse. However, for Flash with the normal prior on
F, the point-exponential prior performed a little better than the
generalized-binary prior. Again, SINDCLUS and SYMPRES perform noticeably
worse than CoDesymNMF in this setting.</p>
</div>
<div
id="proportion-of-true-factors-that-are-highly-similar-to-an-estimated-factor-2"
class="section level2">
<h2>Proportion of true factors that are highly similar to an estimated
factor</h2>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes == &#39;rep(40, 4)&#39;, score == &#39;prop_true_high_cos_sim&#39;) %&gt;% group_by(analyze, analyze.ebnm_fn) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, analyze.ebnm_fn)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 14 × 3
# Groups:   analyze [9]
   analyze                    analyze.ebnm_fn               avg_result
   &lt;chr&gt;                      &lt;chr&gt;                              &lt;dbl&gt;
 1 codesymnmf                 &lt;NA&gt;                               1    
 2 ebcd                       ebnm::ebnm_generalized_binary      1    
 3 ebcd                       ebnm::ebnm_point_exponential       1    
 4 ebmfcov_diag               ebnm::ebnm_generalized_binary      0.95 
 5 ebmfcov_diag               ebnm::ebnm_point_exponential       0.9  
 6 flash_normalf              ebnm::ebnm_generalized_binary      0.6  
 7 flash_normalf              ebnm::ebnm_point_exponential       1    
 8 gbcd                       ebnm::ebnm_generalized_binary      1    
 9 gbcd                       ebnm::ebnm_point_exponential       0.9  
10 laplace_split_ebmfcov_diag ebnm::ebnm_generalized_binary      1    
11 laplace_split_ebmfcov_diag ebnm::ebnm_point_exponential       1    
12 pca                        &lt;NA&gt;                               0.075
13 sindclus                   &lt;NA&gt;                               0.75 
14 sympres                    &lt;NA&gt;                               0.575</code></pre>
<p>We again see a similar phenomenon to the unbalanced non-overlapping
case.</p>
</div>
</div>
<div id="sparse-overlapping" class="section level1">
<h1>Sparse Overlapping</h1>
<p>I will now consider the sparse, overlapping setting.</p>
<div id="crossproduct-similarity-3" class="section level2">
<h2>Crossproduct Similarity</h2>
<p>This is the average crossproduct similarity for each method:</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_overlap&#39;, score == &#39;crossprod_similarity&#39;) %&gt;% group_by(analyze, analyze.ebnm_fn) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, analyze.ebnm_fn)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 14 × 3
# Groups:   analyze [9]
   analyze                    analyze.ebnm_fn               avg_result
   &lt;chr&gt;                      &lt;chr&gt;                              &lt;dbl&gt;
 1 codesymnmf                 &lt;NA&gt;                               0.981
 2 ebcd                       ebnm::ebnm_generalized_binary      0.989
 3 ebcd                       ebnm::ebnm_point_exponential       0.999
 4 ebmfcov_diag               ebnm::ebnm_generalized_binary      0.991
 5 ebmfcov_diag               ebnm::ebnm_point_exponential       0.924
 6 flash_normalf              ebnm::ebnm_generalized_binary      0.904
 7 flash_normalf              ebnm::ebnm_point_exponential       0.999
 8 gbcd                       ebnm::ebnm_generalized_binary      0.966
 9 gbcd                       ebnm::ebnm_point_exponential       0.983
10 laplace_split_ebmfcov_diag ebnm::ebnm_generalized_binary      0.972
11 laplace_split_ebmfcov_diag ebnm::ebnm_point_exponential       0.994
12 pca                        &lt;NA&gt;                               0.611
13 sindclus                   &lt;NA&gt;                               0.823
14 sympres                    &lt;NA&gt;                               0.941</code></pre>
<p>Interestingly, for many of the empirical Bayes methods, the
point-exponential prior had better performance. The only EB method where
this is not the case is EBMFcov.</p>
</div>
<div
id="proportion-of-true-factors-that-are-highly-similar-to-an-estimated-factor-3"
class="section level2">
<h2>Proportion of true factors that are highly similar to an estimated
factor</h2>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_overlap&#39;, score == &#39;prop_true_high_cos_sim&#39;) %&gt;% group_by(analyze, analyze.ebnm_fn) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, analyze.ebnm_fn)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 14 × 3
# Groups:   analyze [9]
   analyze                    analyze.ebnm_fn               avg_result
   &lt;chr&gt;                      &lt;chr&gt;                              &lt;dbl&gt;
 1 codesymnmf                 &lt;NA&gt;                                0.98
 2 ebcd                       ebnm::ebnm_generalized_binary       0.99
 3 ebcd                       ebnm::ebnm_point_exponential        1   
 4 ebmfcov_diag               ebnm::ebnm_generalized_binary       0.98
 5 ebmfcov_diag               ebnm::ebnm_point_exponential        0.91
 6 flash_normalf              ebnm::ebnm_generalized_binary       0.65
 7 flash_normalf              ebnm::ebnm_point_exponential        1   
 8 gbcd                       ebnm::ebnm_generalized_binary       0.9 
 9 gbcd                       ebnm::ebnm_point_exponential        0.96
10 laplace_split_ebmfcov_diag ebnm::ebnm_generalized_binary       0.88
11 laplace_split_ebmfcov_diag ebnm::ebnm_point_exponential        0.97
12 pca                        &lt;NA&gt;                                0.01
13 sindclus                   &lt;NA&gt;                                0.5 
14 sympres                    &lt;NA&gt;                                0.81</code></pre>
</div>
</div>
<div id="unbalanced-tree-setting" class="section level1">
<h1>Unbalanced Tree Setting</h1>
<p>I will now consider the unbalanced tree setting. This setting also is
one of the hardest settings.</p>
<div id="crossproduct-similarity-4" class="section level2">
<h2>Crossproduct Similarity</h2>
<p>This is the average crossproduct similarity for each method in the
balanced tree setting:</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;unbaltree_4pop&#39;, score == &#39;crossprod_similarity&#39;) %&gt;% group_by(analyze, analyze.ebnm_fn) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, analyze.ebnm_fn)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 14 × 3
# Groups:   analyze [9]
   analyze                    analyze.ebnm_fn               avg_result
   &lt;chr&gt;                      &lt;chr&gt;                              &lt;dbl&gt;
 1 codesymnmf                 &lt;NA&gt;                               0.866
 2 ebcd                       ebnm::ebnm_generalized_binary      0.642
 3 ebcd                       ebnm::ebnm_point_exponential       0.668
 4 ebmfcov_diag               ebnm::ebnm_generalized_binary      0.405
 5 ebmfcov_diag               ebnm::ebnm_point_exponential       0.400
 6 flash_normalf              ebnm::ebnm_generalized_binary      0.856
 7 flash_normalf              ebnm::ebnm_point_exponential       0.558
 8 gbcd                       ebnm::ebnm_generalized_binary      0.864
 9 gbcd                       ebnm::ebnm_point_exponential       0.890
10 laplace_split_ebmfcov_diag ebnm::ebnm_generalized_binary      0.828
11 laplace_split_ebmfcov_diag ebnm::ebnm_point_exponential       0.797
12 pca                        &lt;NA&gt;                               0.444
13 sindclus                   &lt;NA&gt;                               0.838
14 sympres                    &lt;NA&gt;                               0.839</code></pre>
<p>In this setting, we see mixed performance. For EBMFcov, Flash with
normal prior on F, and the point-Laplace initialized EBMFcov, the
point-exponential variants performed worse than the generalized-binary
variants (though in some cases it is only slightly worse). For EBCD and
GBCD, the point-exponential variant performed slightly better.</p>
</div>
<div
id="proportion-of-true-factors-that-are-highly-similar-to-an-estimated-factor-4"
class="section level2">
<h2>Proportion of true factors that are highly similar to an estimated
factor</h2>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;unbaltree_4pop&#39;, score == &#39;prop_true_high_cos_sim&#39;) %&gt;% group_by(analyze, analyze.ebnm_fn) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, analyze.ebnm_fn)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 14 × 3
# Groups:   analyze [9]
   analyze                    analyze.ebnm_fn               avg_result
   &lt;chr&gt;                      &lt;chr&gt;                              &lt;dbl&gt;
 1 codesymnmf                 &lt;NA&gt;                               0.743
 2 ebcd                       ebnm::ebnm_generalized_binary      0.771
 3 ebcd                       ebnm::ebnm_point_exponential       0.8  
 4 ebmfcov_diag               ebnm::ebnm_generalized_binary      0.671
 5 ebmfcov_diag               ebnm::ebnm_point_exponential       0.671
 6 flash_normalf              ebnm::ebnm_generalized_binary      0.6  
 7 flash_normalf              ebnm::ebnm_point_exponential       0.643
 8 gbcd                       ebnm::ebnm_generalized_binary      0.871
 9 gbcd                       ebnm::ebnm_point_exponential       0.929
10 laplace_split_ebmfcov_diag ebnm::ebnm_generalized_binary      0.957
11 laplace_split_ebmfcov_diag ebnm::ebnm_point_exponential       0.914
12 pca                        &lt;NA&gt;                               0.286
13 sindclus                   &lt;NA&gt;                               0.529
14 sympres                    &lt;NA&gt;                               0.514</code></pre>
<p>Again, for Flash with normal prior on F, using the previous metric it
looked like point-exponential performed worse than generalized binary.
But in this metric, it looks like the reverse is true. The same holds
true for GBCD.</p>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span>
Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 4.3.2 (2023-10-31)
Platform: aarch64-apple-darwin20 (64-bit)
Running under: macOS 15.6

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: America/Chicago
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] pheatmap_1.0.12 ggplot2_3.5.2   dplyr_1.1.4     workflowr_1.7.1

loaded via a namespace (and not attached):
 [1] gtable_0.3.6       jsonlite_2.0.0     compiler_4.3.2     promises_1.3.3    
 [5] tidyselect_1.2.1   Rcpp_1.0.14        stringr_1.5.1      git2r_0.33.0      
 [9] callr_3.7.6        later_1.4.2        jquerylib_0.1.4    scales_1.4.0      
[13] yaml_2.3.10        fastmap_1.2.0      R6_2.6.1           generics_0.1.4    
[17] knitr_1.50         tibble_3.3.0       rprojroot_2.0.4    RColorBrewer_1.1-3
[21] bslib_0.9.0        pillar_1.10.2      rlang_1.1.6        utf8_1.2.6        
[25] cachem_1.1.0       stringi_1.8.7      httpuv_1.6.15      xfun_0.52         
[29] getPass_0.2-4      fs_1.6.6           sass_0.4.10        cli_3.6.5         
[33] withr_3.0.2        magrittr_2.0.3     ps_1.7.7           grid_4.3.2        
[37] digest_0.6.37      processx_3.8.4     rstudioapi_0.16.0  lifecycle_1.0.4   
[41] vctrs_0.6.5        evaluate_1.0.4     glue_1.8.0         farver_2.1.2      
[45] whisker_0.4.1      rmarkdown_2.29     httr_1.4.7         tools_4.3.2       
[49] pkgconfig_2.0.3    htmltools_0.5.8.1 </code></pre>
</div>
</div>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
https://docs.mathjax.org/en/latest/web/configuration.html. This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
