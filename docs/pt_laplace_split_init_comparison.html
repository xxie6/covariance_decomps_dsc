<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Annie Xie" />

<meta name="date" content="2025-09-04" />

<title>pt_laplace_split_init_comparison</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.5.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet" />

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/main/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>



<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">covariance_decomps_dsc</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/xxie6/covariance_decomps_dsc">
    <span class="fab fa-github"></span>
     
    Source code
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">pt_laplace_split_init_comparison</h1>
<h4 class="author">Annie Xie</h4>
<h4 class="date">2025-09-04</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span>
workflowr <span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span>
</a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2025-09-22
</p>
<p>
<strong>Checks:</strong> <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 7
<span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> 0
</p>
<p>
<strong>Knit directory:</strong> <code>covariance_decomps_dsc/</code>
<span class="glyphicon glyphicon-question-sign" aria-hidden="true"
title="This is the local directory in which the code in this file was executed.">
</span>
</p>
<p>
This reproducible <a href="https://rmarkdown.rstudio.com">R Markdown</a>
analysis was created with <a
  href="https://github.com/workflowr/workflowr">workflowr</a> (version
1.7.1). The <em>Checks</em> tab describes the reproducibility checks
that were applied when the results were created. The <em>Past
versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguptodate">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>R Markdown file:</strong> up-to-date
</a>
</p>
</div>
<div id="strongRMarkdownfilestronguptodate"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great! Since the R Markdown file has been committed to the Git
repository, you know the exact version of the code that produced these
results.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the
global environment can affect the analysis in your R Markdown file in
unknown ways. For reproduciblity it’s best to always run the code in an
empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20250203code">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Seed:</strong>
<code>set.seed(20250203)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20250203code"
class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20250203)</code> was run prior to running
the code in the R Markdown file. Setting a seed ensures that any results
that rely on randomness, e.g. subsampling or permutations, are
reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Session information:</strong>
recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package
versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be
confident that you successfully produced the results during this
run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr
project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomxxie6covariancedecompsdsctreefd7360aed36deeff5b2c61fd6b7df561868f5b92targetblankfd7360aa">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Repository version:</strong>
<a href="https://github.com/xxie6/covariance_decomps_dsc/tree/fd7360aed36deeff5b2c61fd6b7df561868f5b92" target="_blank">fd7360a</a>
</a>
</p>
</div>
<div
id="strongRepositoryversionstrongahrefhttpsgithubcomxxie6covariancedecompsdsctreefd7360aed36deeff5b2c61fd6b7df561868f5b92targetblankfd7360aa"
class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development
and connecting the code version to the results is critical for
reproducibility.
</p>
<p>
The results in this page were generated with repository version
<a href="https://github.com/xxie6/covariance_decomps_dsc/tree/fd7360aed36deeff5b2c61fd6b7df561868f5b92" target="_blank">fd7360a</a>.
See the <em>Past versions</em> tab to see a history of the changes made
to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for
the analysis have been committed to Git prior to generating the results
(you can use <code>wflow_publish</code> or
<code>wflow_git_commit</code>). workflowr only checks the R Markdown
file, but you know if there are other scripts or data files that it
depends on. Below is the status of the Git repository when the results
were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .DS_Store
    Ignored:    .Rhistory
    Ignored:    data/.DS_Store
    Ignored:    data/adclus_cov_comp_dsc_ex/.DS_Store
    Ignored:    data/adclus_same_init_dsc_ex/.DS_Store
    Ignored:    data/pt_laplace_split_init_ex/.DS_Store

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not
included in this status report because it is ok for generated content to
have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the repository in which changes were
made to the R Markdown
(<code>analysis/pt_laplace_split_init_comparison.Rmd</code>) and HTML
(<code>docs/pt_laplace_split_init_comparison.html</code>) files. If
you’ve configured a remote Git repository (see
<code>?wflow_git_remote</code>), click on the hyperlinks in the table
below to view the files as they were in that past version.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/xxie6/covariance_decomps_dsc/blob/fd7360aed36deeff5b2c61fd6b7df561868f5b92/analysis/pt_laplace_split_init_comparison.Rmd" target="_blank">fd7360a</a>
</td>
<td>
Annie Xie
</td>
<td>
2025-09-22
</td>
<td>
Update analysis of pt-laplace plus splitting initialization
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/xxie6/covariance_decomps_dsc/c308933783c97808492734c2fa3d78f98197461d/docs/pt_laplace_split_init_comparison.html" target="_blank">c308933</a>
</td>
<td>
Annie Xie
</td>
<td>
2025-09-08
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/xxie6/covariance_decomps_dsc/blob/af05184e4928f7dee8a42d53d7a8c31cd0997fc4/analysis/pt_laplace_split_init_comparison.Rmd" target="_blank">af05184</a>
</td>
<td>
Annie Xie
</td>
<td>
2025-09-08
</td>
<td>
Add unbalanced tree setting to comparisons
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/xxie6/covariance_decomps_dsc/f8b66cc7436f8c88afccf342a5a57ea1bae505dc/docs/pt_laplace_split_init_comparison.html" target="_blank">f8b66cc</a>
</td>
<td>
Annie Xie
</td>
<td>
2025-09-08
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/xxie6/covariance_decomps_dsc/blob/47dfdf31b5ad34c3759d21bcd56188a103ce8d1e/analysis/pt_laplace_split_init_comparison.Rmd" target="_blank">47dfdf3</a>
</td>
<td>
Annie Xie
</td>
<td>
2025-09-08
</td>
<td>
Add comparison of methods with same laplace-split initialization
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>In this analysis, I am interested in comparing all the methods when
initialized with the same matrix. I will initialize the methods using a
simpler version of the GBCD initialization – I will run flash with
point-Laplace priors on the scaled Gram matrix. Then I will split the
estimate into its positive and negative components and refit the
weights.</p>
<pre class="r"><code>library(dplyr)
library(ggplot2)
library(ggrepel)
library(pheatmap)</code></pre>
<pre class="r"><code>source(&#39;code/visualization_functions.R&#39;)</code></pre>
</div>
<div id="prepare-the-dsc-data" class="section level1">
<h1>Prepare the DSC data</h1>
<pre class="r"><code>dscout &lt;- readRDS(&quot;data/same_init_dsc_results_df.rds&quot;)
dscout &lt;- dscout %&gt;% filter(initialization == &#39;pt_laplace_split&#39;, initialization.K_factor == 1, (is.na(score.threshold) == TRUE | score.threshold == 0.9))
dim(dscout)</code></pre>
<pre><code>[1] 2200   13</code></pre>
<p>I decided to focus on the variant of SINDCLUS and SYMPRES that does
not explicitly model an intercept. So I clean the data to only include
these variants.</p>
<pre class="r"><code>dscout &lt;- dscout %&gt;% filter((is.na(analyze.additive_term) == TRUE) | (analyze.additive_term == &#39;FALSE&#39;)) %&gt;% select(!(analyze.off_diagonal))</code></pre>
</div>
<div id="balanced-tree-setting" class="section level1">
<h1>Balanced Tree Setting</h1>
<p>I will first consider the balanced tree setting. This setting is one
of the hardest settings due to the non-identifiability of the
representation.</p>
<div id="additive-clustering-methods" class="section level2">
<h2>Additive Clustering Methods</h2>
<p>In this section, I will focus on the additive-clustering style
methods</p>
<div id="crossproduct-similarity" class="section level3">
<h3>Crossproduct Similarity</h3>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;baltree_4pop&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(desc(avg_result))</code></pre>
<pre><code># A tibble: 6 × 2
  analyze       avg_result
  &lt;chr&gt;              &lt;dbl&gt;
1 sindclus           1    
2 sympres            1    
3 codesymnmf         0.998
4 ebmfcov_diag       0.996
5 ebcd               0.991
6 flash_normalf      0.795</code></pre>
<p>EBMFcov and EBCD with this initialization have significantly improved
performance. Flash with normal prior on F also has improved performance,
but the performance is still worse than the other methods. This is not
entirely surprising as if I recall correctly, the method prefers the
clustered representation to the tree representation. SINDCLUS and
SYMPRES also significantly improved.</p>
<p>These are histograms of the crossproduct similarity measurements for
each methods:</p>
<pre class="r"><code>plot_crossprod_hist &lt;- function(df, method){
  hist(df[df$analyze == method,]$score.result, main = method, xlab = &#39;Crossproduct Similarity&#39;)
}</code></pre>
<pre class="r"><code>dscout_baltree &lt;- dscout %&gt;% filter(simulate == &#39;baltree_4pop&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE))</code></pre>
<pre class="r"><code>all_methods &lt;- unique(dscout$analyze)

par(mfrow = c(2, 3))
par(mar = c(4, 4, 2, 1)) 
for (i in all_methods){
  plot_crossprod_hist(dscout_baltree, i)
}</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-8-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-8-1">
Past versions of unnamed-chunk-8-1.png
</button>
</p>
<div id="fig-unnamed-chunk-8-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/xxie6/covariance_decomps_dsc/blob/f8b66cc7436f8c88afccf342a5a57ea1bae505dc/docs/figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-8-1.png" target="_blank">f8b66cc</a>
</td>
<td>
Annie Xie
</td>
<td>
2025-09-08
</td>
</tr>
</tbody>
</table>
</div>
</div>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
</div>
<div id="proportions" class="section level3">
<h3>Proportions</h3>
<p>In this section, we consider two metrics: 1) the proportion of the
estimated factors which are highly similar to a true factor 2) the
proportion of true factors that are highly similar to at least one
estimated factor. Note that in the first proportion, it is possible that
multiple estimates are similar to the same true factor – perhaps to
avoid this, the threshold for “highly similar” should be really high,
e.g. 0.99.</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;baltree_4pop&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 12 × 3
# Groups:   analyze [6]
   analyze       score                  avg_result
   &lt;chr&gt;         &lt;chr&gt;                       &lt;dbl&gt;
 1 codesymnmf    prop_est_high_cos_sim       1    
 2 codesymnmf    prop_true_high_cos_sim      1    
 3 ebcd          prop_est_high_cos_sim       0.986
 4 ebcd          prop_true_high_cos_sim      0.971
 5 ebmfcov_diag  prop_est_high_cos_sim       0.986
 6 ebmfcov_diag  prop_true_high_cos_sim      0.986
 7 flash_normalf prop_est_high_cos_sim       1    
 8 flash_normalf prop_true_high_cos_sim      0.7  
 9 sindclus      prop_est_high_cos_sim       1    
10 sindclus      prop_true_high_cos_sim      1    
11 sympres       prop_est_high_cos_sim       1    
12 sympres       prop_true_high_cos_sim      1    </code></pre>
<p>For most methods, the proportions are comparable. For Flash with
normal prior on F, prop_est_high_cos_sim = 1 and prop_true_high_cos_sim
= 0.7. This suggests that the method is not returning any extraneous
factors, but it is still missing some of the underlying structure.</p>
<pre class="r"><code>prop_data_df &lt;- dscout %&gt;% filter(simulate == &#39;baltree_4pop&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre class="r"><code>prop_est_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

prop_true_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_true_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

methods &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;analyze&#39;]]

prop_plot_df &lt;- data.frame(method = methods, prop_est_high_cos_sim_vals = prop_est_high_cos_sim_vals, prop_true_high_cos_sim_vals = prop_true_high_cos_sim_vals)</code></pre>
<pre class="r"><code>ggplot(data = prop_plot_df, aes(x = prop_est_high_cos_sim_vals, y = prop_true_high_cos_sim_vals)) +
  geom_point(size = 3, color = &quot;dodgerblue&quot;) +
  geom_text_repel(
    aes(label = method), 
    box.padding = 0.5, 
    point.padding = 0.5,
    segment.color = &quot;grey50&quot;
  ) +
  labs(title = &quot;&quot;,
       x = &quot;Proportion of Estimate Capturing True Signal&quot;,
       y = &quot;Proportion of True Signals Recovered&quot;) +
  theme_minimal()</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-11-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="symmetric-nmf-methods" class="section level2">
<h2>symmetric NMF methods</h2>
<p>In this section, I will focus on the symmetric-NMF-style methods</p>
<div id="crossproduct-similarity-1" class="section level3">
<h3>Crossproduct Similarity</h3>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;baltree_4pop&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(desc(avg_result))</code></pre>
<pre><code># A tibble: 6 × 2
  analyze       avg_result
  &lt;chr&gt;              &lt;dbl&gt;
1 sindclus           1    
2 sympres            1    
3 codesymnmf         0.998
4 ebmfcov_diag       0.983
5 ebcd               0.849
6 flash_normalf      0.551</code></pre>
<p>EBCD and Flash with normal prior on F perform worse with the
point-exponential prior vs the generalized binary prior. This is not
entirely surprising, as in general, these methods don’t seem to prefer
tree representations. Furthermore, the point-exponential prior has more
flexibility, and thus the methods may converge to different
solutions.</p>
<p>These are histograms of the crossproduct similarity measurements for
each methods:</p>
<pre class="r"><code>dscout_baltree &lt;- dscout %&gt;% filter(simulate == &#39;baltree_4pop&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE))</code></pre>
<pre class="r"><code>#all_methods &lt;- unique(dscout$analyze)

par(mfrow = c(2, 3))
par(mar = c(4, 4, 2, 1)) 
for (i in all_methods){
  plot_crossprod_hist(dscout_baltree, i)
}</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-14-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
</div>
<div id="proportions-1" class="section level3">
<h3>Proportions</h3>
<p>In this section, we consider two metrics: 1) the proportion of the
estimated factors which are highly similar to a true factor 2) the
proportion of true factors that are highly similar to at least one
estimated factor. Note that in the first proportion, it is possible that
multiple estimates are similar to the same true factor – perhaps to
avoid this, the threshold for “highly similar” should be really high,
e.g. 0.99.</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;baltree_4pop&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 12 × 3
# Groups:   analyze [6]
   analyze       score                  avg_result
   &lt;chr&gt;         &lt;chr&gt;                       &lt;dbl&gt;
 1 codesymnmf    prop_est_high_cos_sim       1    
 2 codesymnmf    prop_true_high_cos_sim      1    
 3 ebcd          prop_est_high_cos_sim       0.714
 4 ebcd          prop_true_high_cos_sim      0.771
 5 ebmfcov_diag  prop_est_high_cos_sim       1    
 6 ebmfcov_diag  prop_true_high_cos_sim      1    
 7 flash_normalf prop_est_high_cos_sim       1    
 8 flash_normalf prop_true_high_cos_sim      0.8  
 9 sindclus      prop_est_high_cos_sim       1    
10 sindclus      prop_true_high_cos_sim      1    
11 sympres       prop_est_high_cos_sim       1    
12 sympres       prop_true_high_cos_sim      1    </code></pre>
<p>For CoDesymNMF, prop_est_high_cos_sim and prop_true_high_cos_sim are
both equal to 1, suggesting that the method does not return any factors
containing noise (though it is possible the method is returning
duplicate factors). EBMFcov also has prop_est_high_cos_sim and
prop_true_high_cos_sim both equal to 1. For the other methods, it seems
like there is a significant number of factors that are not highly
similar to a true factor.</p>
<pre class="r"><code>prop_data_df &lt;- dscout %&gt;% filter(simulate == &#39;baltree_4pop&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre class="r"><code>prop_est_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

prop_true_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_true_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

methods &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;analyze&#39;]]

prop_plot_df &lt;- data.frame(method = methods, prop_est_high_cos_sim_vals = prop_est_high_cos_sim_vals, prop_true_high_cos_sim_vals = prop_true_high_cos_sim_vals)</code></pre>
<pre class="r"><code>ggplot(data = prop_plot_df, aes(x = prop_est_high_cos_sim_vals, y = prop_true_high_cos_sim_vals)) +
  geom_point(size = 3, color = &quot;dodgerblue&quot;) +
  geom_text_repel(
    aes(label = method), 
    box.padding = 0.5, 
    point.padding = 0.5,
    segment.color = &quot;grey50&quot;
  ) +
  labs(title = &quot;&quot;,
       x = &quot;Proportion of Estimate Capturing True Signal&quot;,
       y = &quot;Proportion of True Signals Recovered&quot;) +
  theme_minimal()</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-17-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
</div>
<div id="unbalanced-non-overlapping" class="section level1">
<h1>Unbalanced Non-overlapping</h1>
<p>I will now consider the unbalanced non-overlapping setting. This
setting should be the easiest of the four settings.</p>
<div id="additive-clustering-methods-1" class="section level2">
<h2>Additive Clustering Methods</h2>
<p>In this section, I will focus on the additive-clustering style
methods</p>
<div id="crossproduct-similarity-2" class="section level3">
<h3>Crossproduct Similarity</h3>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes != &#39;rep(40, 4)&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(desc(avg_result))</code></pre>
<pre><code># A tibble: 6 × 2
  analyze       avg_result
  &lt;chr&gt;              &lt;dbl&gt;
1 sindclus           1    
2 sympres            1    
3 flash_normalf      1.00 
4 ebcd               1.00 
5 ebmfcov_diag       1.00 
6 codesymnmf         0.999</code></pre>
<p>For most of the empirical Bayes methods, the performance is the same
as when the methods use their built-in initialization procedures. Flash
with normal prior on F showed improved performance (before the
crossproduct similarity was 0.973). CoDesymNMF also has the same
performance. SINDCLUS and SYMPRES also have improved performance (before
the crossproduct similarities were 0.832 and 0.848, respectively).</p>
<p>These are histograms of the crossproduct similarity measurements for
each methods:</p>
<pre class="r"><code>dscout_unbal_nonoverlap &lt;- dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes != &#39;rep(40, 4)&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE))</code></pre>
<pre class="r"><code>#all_methods &lt;- unique(dscout$analyze)

par(mfrow = c(2, 3))
par(mar = c(4, 4, 2, 1)) 
for (i in all_methods){
  plot_crossprod_hist(dscout_unbal_nonoverlap, i)
}</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-20-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
</div>
<div id="proportions-2" class="section level3">
<h3>Proportions</h3>
<p>In this section, we consider two metrics: 1) the proportion of the
estimated factors which are highly similar to a true factor 2) the
proportion of true factors that are highly similar to at least one
estimated factor. Note that in the first proportion, it is possible that
multiple estimates are similar to the same true factor – perhaps to
avoid this, the threshold for “highly similar” should be really high,
e.g. 0.99.</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes != &#39;rep(40, 4)&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 12 × 3
# Groups:   analyze [6]
   analyze       score                  avg_result
   &lt;chr&gt;         &lt;chr&gt;                       &lt;dbl&gt;
 1 codesymnmf    prop_est_high_cos_sim       0.663
 2 codesymnmf    prop_true_high_cos_sim      1    
 3 ebcd          prop_est_high_cos_sim       0.663
 4 ebcd          prop_true_high_cos_sim      1    
 5 ebmfcov_diag  prop_est_high_cos_sim       0.722
 6 ebmfcov_diag  prop_true_high_cos_sim      1    
 7 flash_normalf prop_est_high_cos_sim       0.707
 8 flash_normalf prop_true_high_cos_sim      1    
 9 sindclus      prop_est_high_cos_sim       0.709
10 sindclus      prop_true_high_cos_sim      1    
11 sympres       prop_est_high_cos_sim       0.663
12 sympres       prop_true_high_cos_sim      1    </code></pre>
<p>CoDesymNMF has prop_est_high_cos_sim = 0.663, but
prop_true_high_cos_sim = 1, which suggests the initialization has more
than four factors. With this is mind, we see that all of the methods
return extra factors. Ideally the empirical Bayes methods would be able
to get rid of extra factors. But in my experience, especially when
working in the covariance space, the methods add extra factors.
Furthermore, I’ve found that the generalized-binary prior is more
sensitive to initialization and does not always shrink small values.</p>
<pre class="r"><code>prop_data_df &lt;- dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes != &#39;rep(40, 4)&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre class="r"><code>prop_est_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

prop_true_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_true_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

methods &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;analyze&#39;]]

prop_plot_df &lt;- data.frame(method = methods, prop_est_high_cos_sim_vals = prop_est_high_cos_sim_vals, prop_true_high_cos_sim_vals = prop_true_high_cos_sim_vals)</code></pre>
<pre class="r"><code>ggplot(data = prop_plot_df, aes(x = prop_est_high_cos_sim_vals, y = prop_true_high_cos_sim_vals)) +
  geom_point(size = 3, color = &quot;dodgerblue&quot;) +
  geom_text_repel(
    aes(label = method), 
    box.padding = 0.5, 
    point.padding = 0.5,
    segment.color = &quot;grey50&quot;
  ) +
  labs(title = &quot;&quot;,
       x = &quot;Proportion of Estimate Capturing True Signal&quot;,
       y = &quot;Proportion of True Signals Recovered&quot;) +
  theme_minimal()</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-23-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="symmetric-nmf-methods-1" class="section level2">
<h2>symmetric NMF methods</h2>
<p>In this section, I will focus on the symmetric-NMF-style methods</p>
<div id="crossproduct-similarity-3" class="section level3">
<h3>Crossproduct Similarity</h3>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes != &#39;rep(40, 4)&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(desc(avg_result))</code></pre>
<pre><code># A tibble: 6 × 2
  analyze       avg_result
  &lt;chr&gt;              &lt;dbl&gt;
1 sindclus           1    
2 sympres            1    
3 flash_normalf      1.00 
4 ebcd               1.00 
5 ebmfcov_diag       0.999
6 codesymnmf         0.999</code></pre>
<p>We see similar trends to the additive-clustering-style methods – the
EB methods had comparable performance and the ADCLUS methods saw
improved performance.</p>
<p>These are histograms of the crossproduct similarity measurements for
each methods:</p>
<pre class="r"><code>plot_crossprod_hist &lt;- function(df, method){
  hist(df[df$analyze == method,]$score.result, main = method, xlab = &#39;Crossproduct Similarity&#39;)
}</code></pre>
<pre class="r"><code>dscout_unbal_nonoverlap &lt;- dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes != &#39;rep(40, 4)&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE))</code></pre>
<pre class="r"><code>#all_methods &lt;- unique(dscout$analyze)

par(mfrow = c(2, 3))
par(mar = c(4, 4, 2, 1)) 
for (i in all_methods){
  plot_crossprod_hist(dscout_unbal_nonoverlap, i)
}</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-27-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
</div>
<div id="proportions-3" class="section level3">
<h3>Proportions</h3>
<p>In this section, we consider two metrics: 1) the proportion of the
estimated factors which are highly similar to a true factor 2) the
proportion of true factors that are highly similar to at least one
estimated factor. Note that in the first proportion, it is possible that
multiple estimates are similar to the same true factor – perhaps to
avoid this, the threshold for “highly similar” should be really high,
e.g. 0.99.</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes != &#39;rep(40, 4)&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 12 × 3
# Groups:   analyze [6]
   analyze       score                  avg_result
   &lt;chr&gt;         &lt;chr&gt;                       &lt;dbl&gt;
 1 codesymnmf    prop_est_high_cos_sim       0.663
 2 codesymnmf    prop_true_high_cos_sim      1    
 3 ebcd          prop_est_high_cos_sim       0.663
 4 ebcd          prop_true_high_cos_sim      1    
 5 ebmfcov_diag  prop_est_high_cos_sim       1    
 6 ebmfcov_diag  prop_true_high_cos_sim      1    
 7 flash_normalf prop_est_high_cos_sim       1    
 8 flash_normalf prop_true_high_cos_sim      1    
 9 sindclus      prop_est_high_cos_sim       0.709
10 sindclus      prop_true_high_cos_sim      1    
11 sympres       prop_est_high_cos_sim       0.663
12 sympres       prop_true_high_cos_sim      1    </code></pre>
<p>In this case, EBMFcov and Flash with normal prior on F have
prop_est_high_cos_sim and prop_true_high_cos_sim both equal to 1,
suggesting the methods can return the correct number of components
despite being given more. All of the methods have prop_true_high_cos_sim
equal to 1 but prop_est_high_cos_sim less than 1, which suggests that
the other methods are returning extra factors.</p>
<pre class="r"><code>prop_data_df &lt;- dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes != &#39;rep(40, 4)&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre class="r"><code>prop_est_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

prop_true_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_true_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

methods &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;analyze&#39;]]

prop_plot_df &lt;- data.frame(method = methods, prop_est_high_cos_sim_vals = prop_est_high_cos_sim_vals, prop_true_high_cos_sim_vals = prop_true_high_cos_sim_vals)</code></pre>
<pre class="r"><code>ggplot(data = prop_plot_df, aes(x = prop_est_high_cos_sim_vals, y = prop_true_high_cos_sim_vals)) +
  geom_point(size = 3, color = &quot;dodgerblue&quot;) +
  geom_text_repel(
    aes(label = method), 
    box.padding = 0.5, 
    point.padding = 0.5,
    segment.color = &quot;grey50&quot;
  ) +
  labs(title = &quot;&quot;,
       x = &quot;Proportion of Estimate Capturing True Signal&quot;,
       y = &quot;Proportion of True Signals Recovered&quot;) +
  theme_minimal()</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-30-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
</div>
<div id="balanced-non-overlapping" class="section level1">
<h1>Balanced Non-overlapping</h1>
<p>I will now consider the balanced non-overlapping setting. This
setting should be harder than the unbalanced non-overlapping
setting.</p>
<div id="additive-clustering-methods-2" class="section level2">
<h2>Additive Clustering Methods</h2>
<p>In this section, I will focus on the additive-clustering style
methods</p>
<div id="crossproduct-similarity-4" class="section level3">
<h3>Crossproduct Similarity</h3>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes == &#39;rep(40, 4)&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(desc(avg_result))</code></pre>
<pre><code># A tibble: 6 × 2
  analyze       avg_result
  &lt;chr&gt;              &lt;dbl&gt;
1 sindclus           1    
2 sympres            1    
3 ebcd               1.00 
4 ebmfcov_diag       1.00 
5 codesymnmf         1.00 
6 flash_normalf      0.995</code></pre>
<p>Flash with normal prior on <span class="math inline">\(F\)</span>,
EBMFcov, SINDCLUS, and SYMPRES have a noticeable improvement in
performance.</p>
<p>These are histograms of the crossproduct similarity measurements for
each methods:</p>
<pre class="r"><code>dscout_bal_nonoverlap &lt;- dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes == &#39;rep(40, 4)&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE))</code></pre>
<pre class="r"><code>#all_methods &lt;- unique(dscout$analyze)

par(mfrow = c(2, 3))
par(mar = c(4, 4, 2, 1)) 
for (i in all_methods){
  plot_crossprod_hist(dscout_bal_nonoverlap, i)
}</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-33-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-33-1">
Past versions of unnamed-chunk-33-1.png
</button>
</p>
<div id="fig-unnamed-chunk-33-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/xxie6/covariance_decomps_dsc/blob/f8b66cc7436f8c88afccf342a5a57ea1bae505dc/docs/figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-33-1.png" target="_blank">f8b66cc</a>
</td>
<td>
Annie Xie
</td>
<td>
2025-09-08
</td>
</tr>
</tbody>
</table>
</div>
</div>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
</div>
<div id="proportions-4" class="section level3">
<h3>Proportions</h3>
<p>In this section, we consider two metrics: 1) the proportion of the
estimated factors which are highly similar to a true factor 2) the
proportion of true factors that are highly similar to at least one
estimated factor. Note that in the first proportion, it is possible that
multiple estimates are similar to the same true factor – perhaps to
avoid this, the threshold for “highly similar” should be really high,
e.g. 0.99.</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes == &#39;rep(40, 4)&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 12 × 3
# Groups:   analyze [6]
   analyze       score                  avg_result
   &lt;chr&gt;         &lt;chr&gt;                       &lt;dbl&gt;
 1 codesymnmf    prop_est_high_cos_sim       0.731
 2 codesymnmf    prop_true_high_cos_sim      1    
 3 ebcd          prop_est_high_cos_sim       0.719
 4 ebcd          prop_true_high_cos_sim      1    
 5 ebmfcov_diag  prop_est_high_cos_sim       0.774
 6 ebmfcov_diag  prop_true_high_cos_sim      1    
 7 flash_normalf prop_est_high_cos_sim       0.781
 8 flash_normalf prop_true_high_cos_sim      0.975
 9 sindclus      prop_est_high_cos_sim       0.719
10 sindclus      prop_true_high_cos_sim      1    
11 sympres       prop_est_high_cos_sim       0.719
12 sympres       prop_true_high_cos_sim      1    </code></pre>
<p>CoDesymNMF has prop_est_high_cos_sim = 0.731, but
prop_true_high_cos_sim = 1, which suggests the initialization has more
than four factors. With this is mind, we see that all of the methods
return extra factors.</p>
<pre class="r"><code>prop_data_df &lt;- dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes == &#39;rep(40, 4)&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre class="r"><code>prop_est_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

prop_true_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_true_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

methods &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;analyze&#39;]]

prop_plot_df &lt;- data.frame(method = methods, prop_est_high_cos_sim_vals = prop_est_high_cos_sim_vals, prop_true_high_cos_sim_vals = prop_true_high_cos_sim_vals)</code></pre>
<pre class="r"><code>ggplot(data = prop_plot_df, aes(x = prop_est_high_cos_sim_vals, y = prop_true_high_cos_sim_vals)) +
  geom_point(size = 3, color = &quot;dodgerblue&quot;) +
  geom_text_repel(
    aes(label = method), 
    box.padding = 0.5, 
    point.padding = 0.5,
    segment.color = &quot;grey50&quot;
  ) +
  labs(title = &quot;&quot;,
       x = &quot;Proportion of Estimate Capturing True Signal&quot;,
       y = &quot;Proportion of True Signals Recovered&quot;) +
  theme_minimal()</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-36-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="symmetric-nmf-methods-2" class="section level2">
<h2>symmetric NMF methods</h2>
<p>In this section, I will focus on the symmetric-NMF-style methods</p>
<div id="crossproduct-similarity-5" class="section level3">
<h3>Crossproduct Similarity</h3>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes == &#39;rep(40, 4)&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(desc(avg_result))</code></pre>
<pre><code># A tibble: 6 × 2
  analyze       avg_result
  &lt;chr&gt;              &lt;dbl&gt;
1 sindclus           1    
2 sympres            1    
3 flash_normalf      1.00 
4 ebcd               1.00 
5 codesymnmf         1.00 
6 ebmfcov_diag       0.999</code></pre>
<p>EBMFcov had a noticeable improvement. The other methods perform
comparably to the versions which utilize their built-in
initializations.</p>
<p>These are histograms of the crossproduct similarity measurements for
each methods:</p>
<pre class="r"><code>dscout_bal_nonoverlap &lt;- dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes == &#39;rep(40, 4)&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE))</code></pre>
<pre class="r"><code>#all_methods &lt;- unique(dscout$analyze)

par(mfrow = c(2, 3))
par(mar = c(4, 4, 2, 1)) 
for (i in all_methods){
  plot_crossprod_hist(dscout_bal_nonoverlap, i)
}</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-39-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
</div>
<div id="proportions-5" class="section level3">
<h3>Proportions</h3>
<p>In this section, we consider two metrics: 1) the proportion of the
estimated factors which are highly similar to a true factor 2) the
proportion of true factors that are highly similar to at least one
estimated factor. Note that in the first proportion, it is possible that
multiple estimates are similar to the same true factor – perhaps to
avoid this, the threshold for “highly similar” should be really high,
e.g. 0.99.</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes == &#39;rep(40, 4)&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 12 × 3
# Groups:   analyze [6]
   analyze       score                  avg_result
   &lt;chr&gt;         &lt;chr&gt;                       &lt;dbl&gt;
 1 codesymnmf    prop_est_high_cos_sim       0.731
 2 codesymnmf    prop_true_high_cos_sim      1    
 3 ebcd          prop_est_high_cos_sim       0.719
 4 ebcd          prop_true_high_cos_sim      1    
 5 ebmfcov_diag  prop_est_high_cos_sim       0.98 
 6 ebmfcov_diag  prop_true_high_cos_sim      1    
 7 flash_normalf prop_est_high_cos_sim       1    
 8 flash_normalf prop_true_high_cos_sim      1    
 9 sindclus      prop_est_high_cos_sim       0.719
10 sindclus      prop_true_high_cos_sim      1    
11 sympres       prop_est_high_cos_sim       0.719
12 sympres       prop_true_high_cos_sim      1    </code></pre>
<p>Almost all of the methods have prop_true_high_cos_sim = 1 and
prop_est_high_cos_sim less than 1, suggesting the initialization has
more than four factors. As a result, the proportions suggest that most
of methods return extra factors. However, Flash with normal prior on F
has both proportions equal to 1, so this suggests the method is able to
recover the correct number of components. In addition,
prop_est_high_cos_sim for EBMFcov is very close to 1, so it seems like
it doesn’t happen that often for EBMFcov.</p>
<pre class="r"><code>prop_data_df &lt;- dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes != &#39;rep(40, 4)&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre class="r"><code>prop_est_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

prop_true_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_true_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

methods &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;analyze&#39;]]

prop_plot_df &lt;- data.frame(method = methods, prop_est_high_cos_sim_vals = prop_est_high_cos_sim_vals, prop_true_high_cos_sim_vals = prop_true_high_cos_sim_vals)</code></pre>
<pre class="r"><code>ggplot(data = prop_plot_df, aes(x = prop_est_high_cos_sim_vals, y = prop_true_high_cos_sim_vals)) +
  geom_point(size = 3, color = &quot;dodgerblue&quot;) +
  geom_text_repel(
    aes(label = method), 
    box.padding = 0.5, 
    point.padding = 0.5,
    segment.color = &quot;grey50&quot;
  ) +
  labs(title = &quot;&quot;,
       x = &quot;Proportion of Estimate Capturing True Signal&quot;,
       y = &quot;Proportion of True Signals Recovered&quot;) +
  theme_minimal()</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-42-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-42-1">
Past versions of unnamed-chunk-42-1.png
</button>
</p>
<div id="fig-unnamed-chunk-42-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/xxie6/covariance_decomps_dsc/blob/c308933783c97808492734c2fa3d78f98197461d/docs/figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-42-1.png" target="_blank">c308933</a>
</td>
<td>
Annie Xie
</td>
<td>
2025-09-08
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</div>
</div>
<div id="sparse-overlapping" class="section level1">
<h1>Sparse Overlapping</h1>
<p>I will now consider the sparse, overlapping setting.</p>
<div id="additive-clustering-methods-3" class="section level2">
<h2>Additive Clustering Methods</h2>
<p>In this section, I will focus on the additive-clustering style
methods</p>
<div id="crossproduct-similarity-6" class="section level3">
<h3>Crossproduct Similarity</h3>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_overlap&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(desc(avg_result))</code></pre>
<pre><code># A tibble: 6 × 2
  analyze       avg_result
  &lt;chr&gt;              &lt;dbl&gt;
1 sympres            0.992
2 codesymnmf         0.984
3 sindclus           0.980
4 ebcd               0.978
5 ebmfcov_diag       0.972
6 flash_normalf      0.928</code></pre>
<p>SINDCLUS and SYMPRES saw improvements. EBCD and EBMFcov saw small
decreases in performance.</p>
<p>These are histograms of the crossproduct similarity measurements for
each methods:</p>
<pre class="r"><code>dscout_overlap &lt;- dscout %&gt;% filter(simulate == &#39;group_overlap&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE))</code></pre>
<pre class="r"><code>#all_methods &lt;- unique(dscout$analyze)

par(mfrow = c(2, 3))
par(mar = c(4, 4, 2, 1)) 
for (i in all_methods){
  plot_crossprod_hist(dscout_overlap, i)
}</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-45-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
</div>
<div id="proportions-6" class="section level3">
<h3>Proportions</h3>
<p>In this section, we consider two metrics: 1) the proportion of the
estimated factors which are highly similar to a true factor 2) the
proportion of true factors that are highly similar to at least one
estimated factor. Note that in the first proportion, it is possible that
multiple estimates are similar to the same true factor – perhaps to
avoid this, the threshold for “highly similar” should be really high,
e.g. 0.99.</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_overlap&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 12 × 3
# Groups:   analyze [6]
   analyze       score                  avg_result
   &lt;chr&gt;         &lt;chr&gt;                       &lt;dbl&gt;
 1 codesymnmf    prop_est_high_cos_sim       0.551
 2 codesymnmf    prop_true_high_cos_sim      1    
 3 ebcd          prop_est_high_cos_sim       0.450
 4 ebcd          prop_true_high_cos_sim      0.88 
 5 ebmfcov_diag  prop_est_high_cos_sim       0.523
 6 ebmfcov_diag  prop_true_high_cos_sim      0.88 
 7 flash_normalf prop_est_high_cos_sim       0.408
 8 flash_normalf prop_true_high_cos_sim      0.67 
 9 sindclus      prop_est_high_cos_sim       0.516
10 sindclus      prop_true_high_cos_sim      0.92 
11 sympres       prop_est_high_cos_sim       0.536
12 sympres       prop_true_high_cos_sim      0.96 </code></pre>
<p>For CoDesymNMF, prop_est_high_cos_sim is less than 1 but
prop_true_high_cos_sim = 1, suggesting the initialization has more than
the true number of components (in this case, 10).</p>
<pre class="r"><code>prop_data_df &lt;- dscout %&gt;% filter(simulate == &#39;group_overlap&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre class="r"><code>prop_est_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

prop_true_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_true_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

methods &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;analyze&#39;]]

prop_plot_df &lt;- data.frame(method = methods, prop_est_high_cos_sim_vals = prop_est_high_cos_sim_vals, prop_true_high_cos_sim_vals = prop_true_high_cos_sim_vals)</code></pre>
<pre class="r"><code>ggplot(data = prop_plot_df, aes(x = prop_est_high_cos_sim_vals, y = prop_true_high_cos_sim_vals)) +
  geom_point(size = 3, color = &quot;dodgerblue&quot;) +
  geom_text_repel(
    aes(label = method), 
    box.padding = 0.5, 
    point.padding = 0.5,
    segment.color = &quot;grey50&quot;
  ) +
  labs(title = &quot;&quot;,
       x = &quot;Proportion of Estimate Capturing True Signal&quot;,
       y = &quot;Proportion of True Signals Recovered&quot;) +
  theme_minimal()</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-48-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="symmetric-nmf-methods-3" class="section level2">
<h2>symmetric NMF methods</h2>
<p>In this section, I will focus on the symmetric-NMF-style methods</p>
<div id="crossproduct-similarity-7" class="section level3">
<h3>Crossproduct Similarity</h3>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_overlap&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(desc(avg_result))</code></pre>
<pre><code># A tibble: 6 × 2
  analyze       avg_result
  &lt;chr&gt;              &lt;dbl&gt;
1 ebcd               0.998
2 ebmfcov_diag       0.994
3 sympres            0.992
4 codesymnmf         0.984
5 flash_normalf      0.983
6 sindclus           0.980</code></pre>
<p>Most methods saw comparable performance or an improvement. Flash with
normal prior on F saw a small decrease in performance. But the method
overall still performs very well.</p>
<p>These are histograms of the crossproduct similarity measurements for
each methods:</p>
<pre class="r"><code>dscout_overlap &lt;- dscout %&gt;% filter(simulate == &#39;group_overlap&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE))</code></pre>
<pre class="r"><code>#all_methods &lt;- unique(dscout$analyze)

par(mfrow = c(2, 3))
par(mar = c(4, 4, 2, 1)) 
for (i in all_methods){
  plot_crossprod_hist(dscout_overlap, i)
}</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-51-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
</div>
<div id="proportions-7" class="section level3">
<h3>Proportions</h3>
<p>In this section, we consider two metrics: 1) the proportion of the
estimated factors which are highly similar to a true factor 2) the
proportion of true factors that are highly similar to at least one
estimated factor. Note that in the first proportion, it is possible that
multiple estimates are similar to the same true factor – perhaps to
avoid this, the threshold for “highly similar” should be really high,
e.g. 0.99.</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_overlap&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 12 × 3
# Groups:   analyze [6]
   analyze       score                  avg_result
   &lt;chr&gt;         &lt;chr&gt;                       &lt;dbl&gt;
 1 codesymnmf    prop_est_high_cos_sim       0.551
 2 codesymnmf    prop_true_high_cos_sim      1    
 3 ebcd          prop_est_high_cos_sim       0.505
 4 ebcd          prop_true_high_cos_sim      1    
 5 ebmfcov_diag  prop_est_high_cos_sim       0.866
 6 ebmfcov_diag  prop_true_high_cos_sim      0.97 
 7 flash_normalf prop_est_high_cos_sim       0.868
 8 flash_normalf prop_true_high_cos_sim      0.9  
 9 sindclus      prop_est_high_cos_sim       0.516
10 sindclus      prop_true_high_cos_sim      0.92 
11 sympres       prop_est_high_cos_sim       0.536
12 sympres       prop_true_high_cos_sim      0.96 </code></pre>
<p>Most of the methods do a good job at recovering most of the factors.
However, it seems like most of the methods are also returning extra
factors.</p>
<pre class="r"><code>prop_data_df &lt;- dscout %&gt;% filter(simulate == &#39;group_overlap&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre class="r"><code>prop_est_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

prop_true_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_true_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

methods &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;analyze&#39;]]

prop_plot_df &lt;- data.frame(method = methods, prop_est_high_cos_sim_vals = prop_est_high_cos_sim_vals, prop_true_high_cos_sim_vals = prop_true_high_cos_sim_vals)</code></pre>
<pre class="r"><code>ggplot(data = prop_plot_df, aes(x = prop_est_high_cos_sim_vals, y = prop_true_high_cos_sim_vals)) +
  geom_point(size = 3, color = &quot;dodgerblue&quot;) +
  geom_text_repel(
    aes(label = method), 
    box.padding = 0.5, 
    point.padding = 0.5,
    segment.color = &quot;grey50&quot;
  ) +
  labs(title = &quot;&quot;,
       x = &quot;Proportion of Estimate Capturing True Signal&quot;,
       y = &quot;Proportion of True Signals Recovered&quot;) +
  theme_minimal()</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-54-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
</div>
<div id="unbalanced-tree-setting" class="section level1">
<h1>Unbalanced Tree Setting</h1>
<p>I will now consider the unbalanced tree setting. This setting is also
one of the hardest settings.</p>
<div id="additive-clustering-methods-4" class="section level2">
<h2>Additive Clustering Methods</h2>
<p>In this section, I will focus on the additive-clustering style
methods</p>
<div id="crossproduct-similarity-8" class="section level3">
<h3>Crossproduct Similarity</h3>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;unbaltree_4pop&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(desc(avg_result))</code></pre>
<pre><code># A tibble: 6 × 2
  analyze       avg_result
  &lt;chr&gt;              &lt;dbl&gt;
1 ebmfcov_diag       0.828
2 codesymnmf         0.826
3 ebcd               0.794
4 flash_normalf      0.754
5 sympres            0.737
6 sindclus           0.732</code></pre>
<p>The initialization helped EBCD and EBMFcov. However, the
initialization did not help the other methods, with the greatest impact
seen in SINDCLUS, SYMPRES, and Flash with a normal prior on F. These
methods with their default initialization had average crossproduct
similarities of 0.838, 0.839, and 0.856, respectively.</p>
<p>These are histograms of the crossproduct similarity measurements for
each methods:</p>
<pre class="r"><code>plot_crossprod_hist &lt;- function(df, method){
  hist(df[df$analyze == method,]$score.result, main = method, xlab = &#39;Crossproduct Similarity&#39;)
}</code></pre>
<pre class="r"><code>dscout_unbaltree &lt;- dscout %&gt;% filter(simulate == &#39;unbaltree_4pop&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE))</code></pre>
<pre class="r"><code>all_methods &lt;- unique(dscout$analyze)

par(mfrow = c(2, 3))
par(mar = c(4, 4, 2, 1)) 
for (i in all_methods){
  plot_crossprod_hist(dscout_unbaltree, i)
}</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-58-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
</div>
<div id="proportions-8" class="section level3">
<h3>Proportions</h3>
<p>In this section, we consider two metrics: 1) the proportion of the
estimated factors which are highly similar to a true factor 2) the
proportion of true factors that are highly similar to at least one
estimated factor. Note that in the first proportion, it is possible that
multiple estimates are similar to the same true factor – perhaps to
avoid this, the threshold for “highly similar” should be really high,
e.g. 0.99.</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;unbaltree_4pop&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 12 × 3
# Groups:   analyze [6]
   analyze       score                  avg_result
   &lt;chr&gt;         &lt;chr&gt;                       &lt;dbl&gt;
 1 codesymnmf    prop_est_high_cos_sim       0.910
 2 codesymnmf    prop_true_high_cos_sim      0.971
 3 ebcd          prop_est_high_cos_sim       0.867
 4 ebcd          prop_true_high_cos_sim      0.857
 5 ebmfcov_diag  prop_est_high_cos_sim       0.910
 6 ebmfcov_diag  prop_true_high_cos_sim      0.957
 7 flash_normalf prop_est_high_cos_sim       0.883
 8 flash_normalf prop_true_high_cos_sim      0.557
 9 sindclus      prop_est_high_cos_sim       0.441
10 sindclus      prop_true_high_cos_sim      0.386
11 sympres       prop_est_high_cos_sim       0.424
12 sympres       prop_true_high_cos_sim      0.357</code></pre>
<p>For Flash with normal prior on F, prop_est_high_cos_sim is quite a
bit higher than prop_true_high_cos_sim, suggesting the method is not
returning too many extraneous factors.</p>
<pre class="r"><code>prop_data_df &lt;- dscout %&gt;% filter(simulate == &#39;unbaltree_4pop&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre class="r"><code>prop_est_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

prop_true_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_true_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

methods &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;analyze&#39;]]

prop_plot_df &lt;- data.frame(method = methods, prop_est_high_cos_sim_vals = prop_est_high_cos_sim_vals, prop_true_high_cos_sim_vals = prop_true_high_cos_sim_vals)</code></pre>
<pre class="r"><code>ggplot(data = prop_plot_df, aes(x = prop_est_high_cos_sim_vals, y = prop_true_high_cos_sim_vals)) +
  geom_point(size = 3, color = &quot;dodgerblue&quot;) +
  geom_text_repel(
    aes(label = method), 
    box.padding = 0.5, 
    point.padding = 0.5,
    segment.color = &quot;grey50&quot;
  ) +
  labs(title = &quot;&quot;,
       x = &quot;Proportion of Estimate Capturing True Signal&quot;,
       y = &quot;Proportion of True Signals Recovered&quot;) +
  theme_minimal()</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-61-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="symmetric-nmf-methods-4" class="section level2">
<h2>symmetric NMF methods</h2>
<p>In this section, I will focus on the symmetric-NMF-style methods</p>
<div id="crossproduct-similarity-9" class="section level3">
<h3>Crossproduct Similarity</h3>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;unbaltree_4pop&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(desc(avg_result))</code></pre>
<pre><code># A tibble: 6 × 2
  analyze       avg_result
  &lt;chr&gt;              &lt;dbl&gt;
1 codesymnmf         0.826
2 ebmfcov_diag       0.797
3 ebcd               0.749
4 sympres            0.737
5 sindclus           0.732
6 flash_normalf      0.558</code></pre>
<p>For all of the EB methods, the point-exponential variant performed
worse than the generalized binary prior variant. Similar to what we saw
before, the initialization only helped EBCD and EBMFcov. The other
methods performed the same or worse with this initialization.</p>
<p>These are histograms of the crossproduct similarity measurements for
each methods:</p>
<pre class="r"><code>dscout_unbaltree &lt;- dscout %&gt;% filter(simulate == &#39;unbaltree_4pop&#39;, score == &#39;crossprod_similarity&#39;, (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE))</code></pre>
<pre class="r"><code>#all_methods &lt;- unique(dscout$analyze)

par(mfrow = c(2, 3))
par(mar = c(4, 4, 2, 1)) 
for (i in all_methods){
  plot_crossprod_hist(dscout_unbaltree, i)
}</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-64-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
</div>
<div id="proportions-9" class="section level3">
<h3>Proportions</h3>
<p>In this section, we consider two metrics: 1) the proportion of the
estimated factors which are highly similar to a true factor 2) the
proportion of true factors that are highly similar to at least one
estimated factor. Note that in the first proportion, it is possible that
multiple estimates are similar to the same true factor – perhaps to
avoid this, the threshold for “highly similar” should be really high,
e.g. 0.99.</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;unbaltree_4pop&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 12 × 3
# Groups:   analyze [6]
   analyze       score                  avg_result
   &lt;chr&gt;         &lt;chr&gt;                       &lt;dbl&gt;
 1 codesymnmf    prop_est_high_cos_sim       0.910
 2 codesymnmf    prop_true_high_cos_sim      0.971
 3 ebcd          prop_est_high_cos_sim       0.730
 4 ebcd          prop_true_high_cos_sim      0.829
 5 ebmfcov_diag  prop_est_high_cos_sim       0.926
 6 ebmfcov_diag  prop_true_high_cos_sim      0.914
 7 flash_normalf prop_est_high_cos_sim       1    
 8 flash_normalf prop_true_high_cos_sim      0.671
 9 sindclus      prop_est_high_cos_sim       0.441
10 sindclus      prop_true_high_cos_sim      0.386
11 sympres       prop_est_high_cos_sim       0.424
12 sympres       prop_true_high_cos_sim      0.357</code></pre>
<p>For Flash with normal prior on F, prop_est_high_cos_sim = 1, which
suggests it is not returning extra factors.</p>
<pre class="r"><code>prop_data_df &lt;- dscout %&gt;% filter(simulate == &#39;unbaltree_4pop&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;), (analyze.ebnm_fn == &#39;ebnm::ebnm_point_exponential&#39; | is.na(analyze.ebnm_fn) == TRUE)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre class="r"><code>prop_est_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

prop_true_high_cos_sim_vals &lt;- prop_data_df[(prop_data_df$score == &#39;prop_true_high_cos_sim&#39;) , ][[&#39;avg_result&#39;]]

methods &lt;- prop_data_df[(prop_data_df$score == &#39;prop_est_high_cos_sim&#39;) , ][[&#39;analyze&#39;]]

prop_plot_df &lt;- data.frame(method = methods, prop_est_high_cos_sim_vals = prop_est_high_cos_sim_vals, prop_true_high_cos_sim_vals = prop_true_high_cos_sim_vals)</code></pre>
<pre class="r"><code>ggplot(data = prop_plot_df, aes(x = prop_est_high_cos_sim_vals, y = prop_true_high_cos_sim_vals)) +
  geom_point(size = 3, color = &quot;dodgerblue&quot;) +
  geom_text_repel(
    aes(label = method), 
    box.padding = 0.5, 
    point.padding = 0.5,
    segment.color = &quot;grey50&quot;
  ) +
  labs(title = &quot;&quot;,
       x = &quot;Proportion of Estimate Capturing True Signal&quot;,
       y = &quot;Proportion of True Signals Recovered&quot;) +
  theme_minimal()</code></pre>
<p><img src="figure/pt_laplace_split_init_comparison.Rmd/unnamed-chunk-67-1.png" width="672" style="display: block; margin: auto;" /></p>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span>
Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 4.3.2 (2023-10-31)
Platform: aarch64-apple-darwin20 (64-bit)
Running under: macOS 15.6

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: America/Chicago
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] pheatmap_1.0.12 ggrepel_0.9.6   ggplot2_3.5.2   dplyr_1.1.4    
[5] workflowr_1.7.1

loaded via a namespace (and not attached):
 [1] gtable_0.3.6       jsonlite_2.0.0     compiler_4.3.2     promises_1.3.3    
 [5] tidyselect_1.2.1   Rcpp_1.0.14        stringr_1.5.1      git2r_0.33.0      
 [9] callr_3.7.6        later_1.4.2        jquerylib_0.1.4    scales_1.4.0      
[13] yaml_2.3.10        fastmap_1.2.0      R6_2.6.1           labeling_0.4.3    
[17] generics_0.1.4     knitr_1.50         tibble_3.3.0       rprojroot_2.0.4   
[21] RColorBrewer_1.1-3 bslib_0.9.0        pillar_1.10.2      rlang_1.1.6       
[25] utf8_1.2.6         cachem_1.1.0       stringi_1.8.7      httpuv_1.6.15     
[29] xfun_0.52          getPass_0.2-4      fs_1.6.6           sass_0.4.10       
[33] cli_3.6.5          withr_3.0.2        magrittr_2.0.3     ps_1.7.7          
[37] grid_4.3.2         digest_0.6.37      processx_3.8.4     rstudioapi_0.16.0 
[41] lifecycle_1.0.4    vctrs_0.6.5        evaluate_1.0.4     glue_1.8.0        
[45] farver_2.1.2       whisker_0.4.1      rmarkdown_2.29     httr_1.4.7        
[49] tools_4.3.2        pkgconfig_2.0.3    htmltools_0.5.8.1 </code></pre>
</div>
</div>
</div>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
https://docs.mathjax.org/en/latest/web/configuration.html. This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
