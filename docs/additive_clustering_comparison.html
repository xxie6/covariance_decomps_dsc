<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Annie Xie" />

<meta name="date" content="2025-09-04" />

<title>additive_clustering_comparison</title>

<script src="site_libs/header-attrs-2.29/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.5.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet" />

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/main/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>



<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">covariance_decomps_dsc</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/xxie6/covariance_decomps_dsc">
    <span class="fab fa-github"></span>
     
    Source code
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">additive_clustering_comparison</h1>
<h4 class="author">Annie Xie</h4>
<h4 class="date">2025-09-04</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span>
workflowr <span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span>
</a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2025-09-08
</p>
<p>
<strong>Checks:</strong> <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 7
<span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> 0
</p>
<p>
<strong>Knit directory:</strong> <code>covariance_decomps_dsc/</code>
<span class="glyphicon glyphicon-question-sign" aria-hidden="true"
title="This is the local directory in which the code in this file was executed.">
</span>
</p>
<p>
This reproducible <a href="https://rmarkdown.rstudio.com">R Markdown</a>
analysis was created with <a
  href="https://github.com/workflowr/workflowr">workflowr</a> (version
1.7.1). The <em>Checks</em> tab describes the reproducibility checks
that were applied when the results were created. The <em>Past
versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguptodate">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>R Markdown file:</strong> up-to-date
</a>
</p>
</div>
<div id="strongRMarkdownfilestronguptodate"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great! Since the R Markdown file has been committed to the Git
repository, you know the exact version of the code that produced these
results.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the
global environment can affect the analysis in your R Markdown file in
unknown ways. For reproduciblity it’s best to always run the code in an
empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20250203code">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Seed:</strong>
<code>set.seed(20250203)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20250203code"
class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20250203)</code> was run prior to running
the code in the R Markdown file. Setting a seed ensures that any results
that rely on randomness, e.g. subsampling or permutations, are
reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Session information:</strong>
recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package
versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be
confident that you successfully produced the results during this
run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongrelative">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>File paths:</strong> relative </a>
</p>
</div>
<div id="strongFilepathsstrongrelative" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Using relative paths to the files within your workflowr
project makes it easier to run your code on other machines.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomxxie6covariancedecompsdsctreeaf05184e4928f7dee8a42d53d7a8c31cd0997fc4targetblankaf05184a">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Repository version:</strong>
<a href="https://github.com/xxie6/covariance_decomps_dsc/tree/af05184e4928f7dee8a42d53d7a8c31cd0997fc4" target="_blank">af05184</a>
</a>
</p>
</div>
<div
id="strongRepositoryversionstrongahrefhttpsgithubcomxxie6covariancedecompsdsctreeaf05184e4928f7dee8a42d53d7a8c31cd0997fc4targetblankaf05184a"
class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development
and connecting the code version to the results is critical for
reproducibility.
</p>
<p>
The results in this page were generated with repository version
<a href="https://github.com/xxie6/covariance_decomps_dsc/tree/af05184e4928f7dee8a42d53d7a8c31cd0997fc4" target="_blank">af05184</a>.
See the <em>Past versions</em> tab to see a history of the changes made
to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for
the analysis have been committed to Git prior to generating the results
(you can use <code>wflow_publish</code> or
<code>wflow_git_commit</code>). workflowr only checks the R Markdown
file, but you know if there are other scripts or data files that it
depends on. Below is the status of the Git repository when the results
were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .DS_Store
    Ignored:    .Rhistory
    Ignored:    data/.DS_Store
    Ignored:    data/adclus_cov_comp_dsc_ex/.DS_Store
    Ignored:    data/adclus_same_init_dsc_ex/.DS_Store

Untracked files:
    Untracked:  analysis/unbalanced_tree_analysis.Rmd

Unstaged changes:
    Modified:   analysis/additive_clustering_comparison_pt2.Rmd
    Modified:   analysis/input_K_comparison_pt2.Rmd
    Modified:   analysis/pt_laplace_split_init_comparison_pt2.Rmd

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not
included in this status report because it is ok for generated content to
have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the repository in which changes were
made to the R Markdown
(<code>analysis/additive_clustering_comparison.Rmd</code>) and HTML
(<code>docs/additive_clustering_comparison.html</code>) files. If you’ve
configured a remote Git repository (see <code>?wflow_git_remote</code>),
click on the hyperlinks in the table below to view the files as they
were in that past version.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/xxie6/covariance_decomps_dsc/blob/af05184e4928f7dee8a42d53d7a8c31cd0997fc4/analysis/additive_clustering_comparison.Rmd" target="_blank">af05184</a>
</td>
<td>
Annie Xie
</td>
<td>
2025-09-08
</td>
<td>
Add unbalanced tree setting to comparisons
</td>
</tr>
<tr>
<td>
html
</td>
<td>
<a href="https://rawcdn.githack.com/xxie6/covariance_decomps_dsc/e21527d9962a9d7badac61614f15e8940b36d7fc/docs/additive_clustering_comparison.html" target="_blank">e21527d</a>
</td>
<td>
Annie Xie
</td>
<td>
2025-09-08
</td>
<td>
Build site.
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/xxie6/covariance_decomps_dsc/blob/bdf9fd32e219145edb2861fc87393e55052f67c0/analysis/additive_clustering_comparison.Rmd" target="_blank">bdf9fd3</a>
</td>
<td>
Annie Xie
</td>
<td>
2025-09-08
</td>
<td>
Add comparison of additive clustering style methods
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>In this analysis, I am interested in comparing the
additive-clustering-style methods from the DSC. These methods include
empirical Bayes methods with the generalized-binary prior and SINDCLUS
and SYMPRES. For each method, we give it the true number of components
for the maximum number of factors to fit.</p>
<pre class="r"><code>library(dplyr)
library(ggplot2)
library(pheatmap)</code></pre>
</div>
<div id="prepare-the-dsc-data" class="section level1">
<h1>Prepare the DSC data</h1>
<pre class="r"><code>dscout &lt;- readRDS(&quot;data/dsc_results_df.rds&quot;)
dim(dscout)</code></pre>
<pre><code>[1] 8000   11</code></pre>
<p>I decided to focus on the backfit variant of the empirical Bayes
matrix factorization methods. I also decided to focus on the variant of
SINDCLUS and SYMPRES that does not explicitly model an intercept. So I
clean the data to only include these variants.</p>
<pre class="r"><code>dscout &lt;- dscout %&gt;% filter((is.na(analyze.additive_term) == TRUE &amp; is.na(analyze.backfit) == TRUE) | (analyze.additive_term == &#39;FALSE&#39; | analyze.backfit == &#39;TRUE&#39;)) %&gt;% select(!(analyze.off_diagonal))</code></pre>
<p>I also filter the methods to only include the ADCLUS methods,
CoDesymNMF, and the empirical Bayes methods which use the
generalized-binary prior. Since this analysis focuses on the comparison
of the additive clustering methods, I wanted to only consider the
generalized-binary prior. I will consider the point-exponential prior in
another analysis.</p>
<pre class="r"><code>dscout &lt;- dscout %&gt;% filter((is.na(analyze.ebnm_fn) == TRUE) | (analyze.ebnm_fn == &#39;ebnm::ebnm_generalized_binary&#39;))</code></pre>
<p>I also filter out other settings we’re not interested in (e.g. the
input <span class="math inline">\(K\)</span> being misspecified).</p>
<pre class="r"><code>dscout &lt;- dscout %&gt;% filter(analyze.Kmax_factor == 1)</code></pre>
</div>
<div id="balanced-tree-setting" class="section level1">
<h1>Balanced Tree Setting</h1>
<p>I will first consider the balanced tree setting. This setting is one
of the hardest settings due to the non-identifiability of the
representation.</p>
<div id="crossproduct-similarity" class="section level2">
<h2>Crossproduct Similarity</h2>
<p>This is the average crossproduct similarity for each method in the
balanced tree setting:</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;baltree_4pop&#39;, score == &#39;crossprod_similarity&#39;) %&gt;% group_by(analyze) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(desc(avg_result))</code></pre>
<pre><code># A tibble: 9 × 2
  analyze                    avg_result
  &lt;chr&gt;                           &lt;dbl&gt;
1 gbcd                            0.996
2 laplace_split_ebmfcov_diag      0.996
3 sindclus                        0.935
4 codesymnmf                      0.931
5 sympres                         0.905
6 flash_normalf                   0.700
7 ebcd                            0.636
8 pca                             0.432
9 ebmfcov_diag                    0.421</code></pre>
<p>GBCD and point-Laplace initialized EBMFcov perform the best, with
average crossproduct similarities exceeding 0.99. We hypothesize that
the point-Laplace initialization is the reason why these two methods
perform so well. SINDCLUS, CoDesymNMF, and SYMPRES also perform quite
well, yielding similarities exceeding 0.90. The other empirical Bayes
methods struggle in this setting. The fact that EBCD struggles is a
little unexpected since EBCD is essentially solving the same problem as
GBCD. If I recall correctly, Flash with normal prior on F does not
prefer the tree representation to the clustered representation, so it
makes sense that it would perform poorly. EBMFcov performs poorly
because it prematurely stops adding factors. The greedy initialization
struggles in the tree setting while the point-Laplace plus splitting
initialization performs really well.</p>
<p>These are histograms of the crossproduct similarity measurements for
each methods:</p>
<pre class="r"><code>plot_crossprod_hist &lt;- function(df, method){
  hist(df[df$analyze == method,]$score.result, main = method, xlab = &#39;Crossproduct Similarity&#39;)
}</code></pre>
<pre class="r"><code>dscout_baltree &lt;- dscout %&gt;% filter(simulate == &#39;baltree_4pop&#39;, score == &#39;crossprod_similarity&#39;)</code></pre>
<pre class="r"><code>all_methods &lt;- unique(dscout$analyze)

par(mfrow = c(3, 3))
par(mar = c(4, 4, 2, 1)) 
for (i in all_methods){
  plot_crossprod_hist(dscout_baltree, i)
}</code></pre>
<p><img src="figure/additive_clustering_comparison.Rmd/unnamed-chunk-10-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-10-1">
Past versions of unnamed-chunk-10-1.png
</button>
</p>
<div id="fig-unnamed-chunk-10-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/xxie6/covariance_decomps_dsc/blob/e21527d9962a9d7badac61614f15e8940b36d7fc/docs/figure/additive_clustering_comparison.Rmd/unnamed-chunk-10-1.png" target="_blank">e21527d</a>
</td>
<td>
Annie Xie
</td>
<td>
2025-09-08
</td>
</tr>
</tbody>
</table>
</div>
</div>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<p>SINDCLUS, SYMPRES, and Flash with a normal prior on F have
crossproduct similarity values which span a considerable range. In my
experience playing around with SINDCLUS and SYMPRES, it is possible to
get very different estimates by chance due to the random steps in their
fitting processes. EBCD performs poorly in all simulations. GBCD attains
nearly perfect recovery in all simulations.</p>
</div>
<div id="proportions" class="section level2">
<h2>Proportions</h2>
<p>In this section, we consider two metrics: 1) the proportion of the
estimated factors which are highly similar to a true factor 2) the
proportion of true factors that are highly similar to at least one
estimated factor. Note that in the first proportion, it is possible that
multiple estimates are similar to the same true factor – perhaps to
avoid this, the threshold for “highly similar” should be really high,
e.g. 0.99.</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;baltree_4pop&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 18 × 3
# Groups:   analyze [9]
   analyze                    score                  avg_result
   &lt;chr&gt;                      &lt;chr&gt;                       &lt;dbl&gt;
 1 codesymnmf                 prop_est_high_cos_sim       0.829
 2 codesymnmf                 prop_true_high_cos_sim      0.871
 3 ebcd                       prop_est_high_cos_sim       0.543
 4 ebcd                       prop_true_high_cos_sim      0.6  
 5 ebmfcov_diag               prop_est_high_cos_sim       1    
 6 ebmfcov_diag               prop_true_high_cos_sim      0.443
 7 flash_normalf              prop_est_high_cos_sim       0.797
 8 flash_normalf              prop_true_high_cos_sim      0.529
 9 gbcd                       prop_est_high_cos_sim       1    
10 gbcd                       prop_true_high_cos_sim      1    
11 laplace_split_ebmfcov_diag prop_est_high_cos_sim       0.986
12 laplace_split_ebmfcov_diag prop_true_high_cos_sim      0.986
13 pca                        prop_est_high_cos_sim       0.143
14 pca                        prop_true_high_cos_sim      0.143
15 sindclus                   prop_est_high_cos_sim       0.971
16 sindclus                   prop_true_high_cos_sim      0.929
17 sympres                    prop_est_high_cos_sim       0.943
18 sympres                    prop_true_high_cos_sim      0.871</code></pre>
<p>For SINDCLUS and SYMPRES, prop_est_high_cos_sim is higher than
prop_true_high_cos_sim. In this case, the methods were given the correct
number of components, so this could suggest that the methods are finding
duplicate (or highly similar) factors. For EBMFcov,
prop_est_high_cos_sim = 1 while prop_true_high_cos_sim = 0.443. This is
because EBMFcov usually only finds three factors, but the three factors
it does find are correlated with three true factors.</p>
</div>
</div>
<div id="unbalanced-non-overlapping" class="section level1">
<h1>Unbalanced Non-overlapping</h1>
<p>I will now consider the unbalanced non-overlapping setting. This
setting should be the easiest of the four settings.</p>
<div id="crossproduct-similarity-1" class="section level2">
<h2>Crossproduct Similarity</h2>
<p>This is the average crossproduct similarity for each method:</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes != &#39;rep(40, 4)&#39;, score == &#39;crossprod_similarity&#39;) %&gt;% group_by(analyze) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(desc(avg_result))</code></pre>
<pre><code># A tibble: 9 × 2
  analyze                    avg_result
  &lt;chr&gt;                           &lt;dbl&gt;
1 ebcd                            1.00 
2 laplace_split_ebmfcov_diag      1.00 
3 ebmfcov_diag                    1.00 
4 gbcd                            1.00 
5 codesymnmf                      0.999
6 pca                             0.988
7 flash_normalf                   0.973
8 sympres                         0.848
9 sindclus                        0.832</code></pre>
<p>Most of the methods have perfect or near perfect recovery of the
structure. However, SINDCLUS and SYMPRES seem to struggle a bit in this
setting.</p>
<p>These are histograms of the crossproduct similarity measurements for
each methods:</p>
<pre class="r"><code>plot_crossprod_hist &lt;- function(df, method){
  hist(df[df$analyze == method,]$score.result, main = method, xlab = &#39;Crossproduct Similarity&#39;)
}</code></pre>
<pre class="r"><code>dscout_unbal_nonoverlap &lt;- dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes != &#39;rep(40, 4)&#39;, score == &#39;crossprod_similarity&#39;)</code></pre>
<pre class="r"><code># all_methods &lt;- unique(dscout$analyze)

par(mfrow = c(3, 3))
par(mar = c(4, 4, 2, 1)) 
for (i in all_methods){
  plot_crossprod_hist(dscout_unbal_nonoverlap, i)
}</code></pre>
<p><img src="figure/additive_clustering_comparison.Rmd/unnamed-chunk-15-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-15-1">
Past versions of unnamed-chunk-15-1.png
</button>
</p>
<div id="fig-unnamed-chunk-15-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/xxie6/covariance_decomps_dsc/blob/e21527d9962a9d7badac61614f15e8940b36d7fc/docs/figure/additive_clustering_comparison.Rmd/unnamed-chunk-15-1.png" target="_blank">e21527d</a>
</td>
<td>
Annie Xie
</td>
<td>
2025-09-08
</td>
</tr>
</tbody>
</table>
</div>
</div>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<p>We again see that SINDCLUS and SYMPRES have crossproduct similarity
values which span a considerable range. This explains why they have
lower average crossproduct similarity values.</p>
</div>
<div id="proportions-1" class="section level2">
<h2>Proportions</h2>
<p>In this section, we consider two metrics: 1) the proportion of the
estimated factors which are highly similar to a true factor 2) the
proportion of true factors that are highly similar to at least one
estimated factor. Note that in the first proportion, it is possible that
multiple estimates are similar to the same true factor – perhaps to
avoid this, the threshold for “highly similar” should be really high,
e.g. 0.99.</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes != &#39;rep(40, 4)&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 18 × 3
# Groups:   analyze [9]
   analyze                    score                  avg_result
   &lt;chr&gt;                      &lt;chr&gt;                       &lt;dbl&gt;
 1 codesymnmf                 prop_est_high_cos_sim       1    
 2 codesymnmf                 prop_true_high_cos_sim      1    
 3 ebcd                       prop_est_high_cos_sim       1    
 4 ebcd                       prop_true_high_cos_sim      1    
 5 ebmfcov_diag               prop_est_high_cos_sim       1    
 6 ebmfcov_diag               prop_true_high_cos_sim      1    
 7 flash_normalf              prop_est_high_cos_sim       0.9  
 8 flash_normalf              prop_true_high_cos_sim      0.9  
 9 gbcd                       prop_est_high_cos_sim       0.781
10 gbcd                       prop_true_high_cos_sim      1    
11 laplace_split_ebmfcov_diag prop_est_high_cos_sim       0.722
12 laplace_split_ebmfcov_diag prop_true_high_cos_sim      1    
13 pca                        prop_est_high_cos_sim       1    
14 pca                        prop_true_high_cos_sim      1    
15 sindclus                   prop_est_high_cos_sim       0.825
16 sindclus                   prop_true_high_cos_sim      0.75 
17 sympres                    prop_est_high_cos_sim       0.825
18 sympres                    prop_true_high_cos_sim      0.75 </code></pre>
<p>In this case, GBCD and point-Laplace initialized EBMFcov have
prop_est_high_cos_sim less than prop_true_high_cos_sim and
prop_true_high_cos_sim = 1. This suggests that these methods are
returning additional factors that are just capturing noise.</p>
</div>
</div>
<div id="balanced-non-overlapping" class="section level1">
<h1>Balanced Non-overlapping</h1>
<p>I will now consider the balanced non-overlapping setting. This
setting should be harder than the unbalanced non-overlapping
setting.</p>
<div id="crossproduct-similarity-2" class="section level2">
<h2>Crossproduct Similarity</h2>
<p>This is the average crossproduct similarity for each method:</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes == &#39;rep(40, 4)&#39;, score == &#39;crossprod_similarity&#39;) %&gt;% group_by(analyze) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(desc(avg_result))</code></pre>
<pre><code># A tibble: 9 × 2
  analyze                    avg_result
  &lt;chr&gt;                           &lt;dbl&gt;
1 ebcd                            1.00 
2 laplace_split_ebmfcov_diag      1.00 
3 codesymnmf                      0.999
4 gbcd                            0.999
5 ebmfcov_diag                    0.967
6 sindclus                        0.927
7 flash_normalf                   0.892
8 sympres                         0.876
9 pca                             0.743</code></pre>
<p>All the methods outperform the baseline, PCA. SYMPRES, and Flash with
a normal prior on F have the lowest performance (besides PCA).</p>
<p>These are histograms of the crossproduct similarity measurements for
each methods:</p>
<pre class="r"><code>plot_crossprod_hist &lt;- function(df, method){
  hist(df[df$analyze == method,]$score.result, main = method, xlab = &#39;Crossproduct Similarity&#39;)
}</code></pre>
<pre class="r"><code>dscout_bal_nonoverlap &lt;- dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes == &#39;rep(40, 4)&#39;, score == &#39;crossprod_similarity&#39;)</code></pre>
<pre class="r"><code># all_methods &lt;- unique(dscout$analyze)

par(mfrow = c(3, 3))
par(mar = c(4, 4, 2, 1)) 
for (i in all_methods){
  plot_crossprod_hist(dscout_bal_nonoverlap, i)
}</code></pre>
<p><img src="figure/additive_clustering_comparison.Rmd/unnamed-chunk-20-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-20-1">
Past versions of unnamed-chunk-20-1.png
</button>
</p>
<div id="fig-unnamed-chunk-20-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/xxie6/covariance_decomps_dsc/blob/e21527d9962a9d7badac61614f15e8940b36d7fc/docs/figure/additive_clustering_comparison.Rmd/unnamed-chunk-20-1.png" target="_blank">e21527d</a>
</td>
<td>
Annie Xie
</td>
<td>
2025-09-08
</td>
</tr>
</tbody>
</table>
</div>
</div>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<p>We again see that SINDCLUS, SYMPRES, and Flash with a normal prior on
F have crossproduct similarity values which span a considerable range.
EBMFcov has very strong performance except for one instance where the
method performs quite poorly.</p>
</div>
<div id="proportions-2" class="section level2">
<h2>Proportions</h2>
<p>In this section, we consider two metrics: 1) the proportion of the
estimated factors which are highly similar to a true factor 2) the
proportion of true factors that are highly similar to at least one
estimated factor. Note that in the first proportion, it is possible that
multiple estimates are similar to the same true factor – perhaps to
avoid this, the threshold for “highly similar” should be really high,
e.g. 0.99.</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_nonoverlap&#39;, simulate.pop_sizes == &#39;rep(40, 4)&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 18 × 3
# Groups:   analyze [9]
   analyze                    score                  avg_result
   &lt;chr&gt;                      &lt;chr&gt;                       &lt;dbl&gt;
 1 codesymnmf                 prop_est_high_cos_sim       1    
 2 codesymnmf                 prop_true_high_cos_sim      1    
 3 ebcd                       prop_est_high_cos_sim       1    
 4 ebcd                       prop_true_high_cos_sim      1    
 5 ebmfcov_diag               prop_est_high_cos_sim       0.967
 6 ebmfcov_diag               prop_true_high_cos_sim      0.95 
 7 flash_normalf              prop_est_high_cos_sim       0.6  
 8 flash_normalf              prop_true_high_cos_sim      0.6  
 9 gbcd                       prop_est_high_cos_sim       0.847
10 gbcd                       prop_true_high_cos_sim      1    
11 laplace_split_ebmfcov_diag prop_est_high_cos_sim       0.774
12 laplace_split_ebmfcov_diag prop_true_high_cos_sim      1    
13 pca                        prop_est_high_cos_sim       0.075
14 pca                        prop_true_high_cos_sim      0.075
15 sindclus                   prop_est_high_cos_sim       0.75 
16 sindclus                   prop_true_high_cos_sim      0.75 
17 sympres                    prop_est_high_cos_sim       0.575
18 sympres                    prop_true_high_cos_sim      0.575</code></pre>
<p>Again, GBCD and point-Laplace initialized EBMFcov have
prop_est_high_cos_sim less than prop_true_high_cos_sim and
prop_true_high_cos_sim = 1.</p>
</div>
</div>
<div id="sparse-overlapping" class="section level1">
<h1>Sparse Overlapping</h1>
<p>I will now consider the sparse, overlapping setting.</p>
<div id="crossproduct-similarity-3" class="section level2">
<h2>Crossproduct Similarity</h2>
<p>This is the average crossproduct similarity for each method:</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_overlap&#39;, score == &#39;crossprod_similarity&#39;) %&gt;% group_by(analyze) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(desc(avg_result))</code></pre>
<pre><code># A tibble: 9 × 2
  analyze                    avg_result
  &lt;chr&gt;                           &lt;dbl&gt;
1 ebmfcov_diag                    0.991
2 ebcd                            0.989
3 codesymnmf                      0.981
4 laplace_split_ebmfcov_diag      0.972
5 gbcd                            0.966
6 sympres                         0.941
7 flash_normalf                   0.904
8 sindclus                        0.823
9 pca                             0.611</code></pre>
<p>All the methods outperform the baseline, PCA. SINDCLUS performs
noticeably worse than the other methods.</p>
<p>These are histograms of the crossproduct similarity measurements for
each methods:</p>
<pre class="r"><code>plot_crossprod_hist &lt;- function(df, method){
  hist(df[df$analyze == method,]$score.result, main = method, xlab = &#39;Crossproduct Similarity&#39;)
}</code></pre>
<pre class="r"><code>dscout_overlap &lt;- dscout %&gt;% filter(simulate == &#39;group_overlap&#39;, score == &#39;crossprod_similarity&#39;)</code></pre>
<pre class="r"><code># all_methods &lt;- unique(dscout$analyze)

par(mfrow = c(3, 3))
par(mar = c(4, 4, 2, 1)) 
for (i in all_methods){
  plot_crossprod_hist(dscout_overlap, i)
}</code></pre>
<p><img src="figure/additive_clustering_comparison.Rmd/unnamed-chunk-25-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>
<button type="button" class="btn btn-default btn-xs btn-workflowr btn-workflowr-fig" data-toggle="collapse" data-target="#fig-unnamed-chunk-25-1">
Past versions of unnamed-chunk-25-1.png
</button>
</p>
<div id="fig-unnamed-chunk-25-1" class="collapse">
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<a href="https://github.com/xxie6/covariance_decomps_dsc/blob/e21527d9962a9d7badac61614f15e8940b36d7fc/docs/figure/additive_clustering_comparison.Rmd/unnamed-chunk-25-1.png" target="_blank">e21527d</a>
</td>
<td>
Annie Xie
</td>
<td>
2025-09-08
</td>
</tr>
</tbody>
</table>
</div>
</div>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<p>Overall, there’s a little more variability in these values than in
the previous sections. The most consistent methods are EBCD and EBMFcov,
which obtain high crossproduct similarity scores nine out of ten times.
CoDesymNMF also has strong performance, obtaining high crossproduct
similarity scores eight out of ten times.</p>
</div>
<div id="proportions-3" class="section level2">
<h2>Proportions</h2>
<p>In this section, we consider two metrics: 1) the proportion of the
estimated factors which are highly similar to a true factor 2) the
proportion of true factors that are highly similar to at least one
estimated factor. Note that in the first proportion, it is possible that
multiple estimates are similar to the same true factor – perhaps to
avoid this, the threshold for “highly similar” should be really high,
e.g. 0.99.</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;group_overlap&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 18 × 3
# Groups:   analyze [9]
   analyze                    score                  avg_result
   &lt;chr&gt;                      &lt;chr&gt;                       &lt;dbl&gt;
 1 codesymnmf                 prop_est_high_cos_sim       0.99 
 2 codesymnmf                 prop_true_high_cos_sim      0.98 
 3 ebcd                       prop_est_high_cos_sim       0.99 
 4 ebcd                       prop_true_high_cos_sim      0.99 
 5 ebmfcov_diag               prop_est_high_cos_sim       0.98 
 6 ebmfcov_diag               prop_true_high_cos_sim      0.98 
 7 flash_normalf              prop_est_high_cos_sim       0.65 
 8 flash_normalf              prop_true_high_cos_sim      0.65 
 9 gbcd                       prop_est_high_cos_sim       0.627
10 gbcd                       prop_true_high_cos_sim      0.9  
11 laplace_split_ebmfcov_diag prop_est_high_cos_sim       0.523
12 laplace_split_ebmfcov_diag prop_true_high_cos_sim      0.88 
13 pca                        prop_est_high_cos_sim       0.01 
14 pca                        prop_true_high_cos_sim      0.01 
15 sindclus                   prop_est_high_cos_sim       0.5  
16 sindclus                   prop_true_high_cos_sim      0.5  
17 sympres                    prop_est_high_cos_sim       0.82 
18 sympres                    prop_true_high_cos_sim      0.81 </code></pre>
<p>Again, GBCD and point-Laplace initialized EBMFcov have
prop_est_high_cos_sim less than prop_true_high_cos_sim. This could
suggest that these methods are returning factors containing noise (I
should double check how many factors these methods end up fitting).</p>
</div>
</div>
<div id="unbalanced-tree-setting" class="section level1">
<h1>Unbalanced Tree Setting</h1>
<p>I will now consider the unbalanced tree setting. This setting also is
one of the hardest settings.</p>
<div id="crossproduct-similarity-4" class="section level2">
<h2>Crossproduct Similarity</h2>
<p>This is the average crossproduct similarity for each method in the
balanced tree setting:</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;unbaltree_4pop&#39;, score == &#39;crossprod_similarity&#39;) %&gt;% group_by(analyze) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(desc(avg_result))</code></pre>
<pre><code># A tibble: 9 × 2
  analyze                    avg_result
  &lt;chr&gt;                           &lt;dbl&gt;
1 codesymnmf                      0.866
2 gbcd                            0.864
3 flash_normalf                   0.856
4 sympres                         0.839
5 sindclus                        0.838
6 laplace_split_ebmfcov_diag      0.828
7 ebcd                            0.642
8 pca                             0.444
9 ebmfcov_diag                    0.405</code></pre>
<p>As expected, the unbalanced tree case is harder than the balanced
tree case. None of the methods have an average crossproduct similarity
value greater than 0.9. CoDesymNMF has the highest performance in this
tree setting with an average crossproduct similarity of 0.866. GBCD had
the second highest performance with a crossproduct similarity of 0.864.
EBMFcov performs worse than our baseline, PCA. Interestingly, flash with
normal prior on F also performs relatively well in this setting; we did
not see this in the balanced tree setting.</p>
<p>These are histograms of the crossproduct similarity measurements for
each methods:</p>
<pre class="r"><code>plot_crossprod_hist &lt;- function(df, method){
  hist(df[df$analyze == method,]$score.result, main = method, xlab = &#39;Crossproduct Similarity&#39;)
}</code></pre>
<pre class="r"><code>dscout_unbaltree &lt;- dscout %&gt;% filter(simulate == &#39;unbaltree_4pop&#39;, score == &#39;crossprod_similarity&#39;)</code></pre>
<pre class="r"><code>all_methods &lt;- unique(dscout$analyze)

par(mfrow = c(3, 3))
par(mar = c(4, 4, 2, 1)) 
for (i in all_methods){
  plot_crossprod_hist(dscout_unbaltree, i)
}</code></pre>
<p><img src="figure/additive_clustering_comparison.Rmd/unnamed-chunk-30-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>par(mfrow = c(1, 1))</code></pre>
<p>It seems like the only method that was able to attain a crossproduct
similarity value greater than 0.95 is point-Laplace initialized
EBMFcov.</p>
</div>
<div id="proportions-4" class="section level2">
<h2>Proportions</h2>
<p>In this section, we consider two metrics: 1) the proportion of the
estimated factors which are highly similar to a true factor 2) the
proportion of true factors that are highly similar to at least one
estimated factor. Note that in the first proportion, it is possible that
multiple estimates are similar to the same true factor – perhaps to
avoid this, the threshold for “highly similar” should be really high,
e.g. 0.99.</p>
<pre class="r"><code>dscout %&gt;% filter(simulate == &#39;unbaltree_4pop&#39;, score %in% c(&#39;prop_est_high_cos_sim&#39;, &#39;prop_true_high_cos_sim&#39;)) %&gt;% group_by(analyze, score) %&gt;% summarise(avg_result = mean(score.result)) %&gt;% arrange(analyze, score)</code></pre>
<pre><code>`summarise()` has grouped output by &#39;analyze&#39;. You can override using the
`.groups` argument.</code></pre>
<pre><code># A tibble: 18 × 3
# Groups:   analyze [9]
   analyze                    score                  avg_result
   &lt;chr&gt;                      &lt;chr&gt;                       &lt;dbl&gt;
 1 codesymnmf                 prop_est_high_cos_sim       0.586
 2 codesymnmf                 prop_true_high_cos_sim      0.743
 3 ebcd                       prop_est_high_cos_sim       0.571
 4 ebcd                       prop_true_high_cos_sim      0.771
 5 ebmfcov_diag               prop_est_high_cos_sim       1    
 6 ebmfcov_diag               prop_true_high_cos_sim      0.671
 7 flash_normalf              prop_est_high_cos_sim       1    
 8 flash_normalf              prop_true_high_cos_sim      0.6  
 9 gbcd                       prop_est_high_cos_sim       0.824
10 gbcd                       prop_true_high_cos_sim      0.871
11 laplace_split_ebmfcov_diag prop_est_high_cos_sim       0.910
12 laplace_split_ebmfcov_diag prop_true_high_cos_sim      0.957
13 pca                        prop_est_high_cos_sim       0.143
14 pca                        prop_true_high_cos_sim      0.286
15 sindclus                   prop_est_high_cos_sim       0.529
16 sindclus                   prop_true_high_cos_sim      0.529
17 sympres                    prop_est_high_cos_sim       0.486
18 sympres                    prop_true_high_cos_sim      0.514</code></pre>
<p>With respect to the metric “proportion of true factors that are
highly similar with an estimated factor”, point-Laplace initialized
EBMFcov has the highest performance. We see that EBMFcov and Flash with
a normal prior on F both have prop_est_high_cos_sim = 1 but
prop_true_high_cos_sim less than 1. This suggests the methods are not
returning extra factors, but they are also missing some true factors. We
also see that for CoDesymNMF, prop_est_high_cos_sim is less than
prop_true_high_cos_sim. In this setting, the methods are given the
correct number of components, so this could suggest that multiple true
factors are highly similar to the same estimated factor (I did set the
threshold to be 0.9, so it is possible to have two true factors which
are similar – but not exactly the same – exceed the similarity threshold
with the same estimated factor. If I set the threshold to 0.99, I would
expect that at most one factor would exceed the threshold).</p>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span>
Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 4.3.2 (2023-10-31)
Platform: aarch64-apple-darwin20 (64-bit)
Running under: macOS 15.6

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: America/Chicago
tzcode source: internal

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] pheatmap_1.0.12 ggplot2_3.5.2   dplyr_1.1.4     workflowr_1.7.1

loaded via a namespace (and not attached):
 [1] gtable_0.3.6       jsonlite_2.0.0     compiler_4.3.2     promises_1.3.3    
 [5] tidyselect_1.2.1   Rcpp_1.0.14        stringr_1.5.1      git2r_0.33.0      
 [9] callr_3.7.6        later_1.4.2        jquerylib_0.1.4    scales_1.4.0      
[13] yaml_2.3.10        fastmap_1.2.0      R6_2.6.1           generics_0.1.4    
[17] knitr_1.50         tibble_3.3.0       rprojroot_2.0.4    RColorBrewer_1.1-3
[21] bslib_0.9.0        pillar_1.10.2      rlang_1.1.6        utf8_1.2.6        
[25] cachem_1.1.0       stringi_1.8.7      httpuv_1.6.15      xfun_0.52         
[29] getPass_0.2-4      fs_1.6.6           sass_0.4.10        cli_3.6.5         
[33] withr_3.0.2        magrittr_2.0.3     ps_1.7.7           grid_4.3.2        
[37] digest_0.6.37      processx_3.8.4     rstudioapi_0.16.0  lifecycle_1.0.4   
[41] vctrs_0.6.5        evaluate_1.0.4     glue_1.8.0         farver_2.1.2      
[45] whisker_0.4.1      rmarkdown_2.29     httr_1.4.7         tools_4.3.2       
[49] pkgconfig_2.0.3    htmltools_0.5.8.1 </code></pre>
</div>
</div>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
https://docs.mathjax.org/en/latest/web/configuration.html. This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
